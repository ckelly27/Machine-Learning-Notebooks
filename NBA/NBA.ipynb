{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z_JdgK41y4X",
        "outputId": "a51c7dac-08c0-4337-eeca-c512aabb6f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nba_api\n",
            "  Downloading nba_api-1.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from nba_api) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from nba_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2025.1.31)\n",
            "Downloading nba_api-1.8.0-py3-none-any.whl (285 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.2/285.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nba_api\n",
            "Successfully installed nba_api-1.8.0\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/swar/nba_api/tree/master\n",
        "%pip install nba_api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nba_api.stats.static import teams\n",
        "from nba_api.stats.endpoints import teamgamelog\n",
        "from nba_api.stats.endpoints import boxscoreadvancedv2\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZKlQ1QXF2GSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6244a66f-9463-43bf-8300-9e4ff83fac95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.models import load_model\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "ZLY1UhptrbP5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teamsJson = teams.get_teams()\n",
        "team_dict = {team['full_name'].lower(): team['id'] for team in teamsJson}\n",
        "\n",
        "def getRecentGames(teamOne, num_games = 10):\n",
        "    teamStatsOne = teamgamelog.TeamGameLog(team_id = team_dict[teamOne]).get_data_frames()[0].head(num_games)\n",
        "\n",
        "    statsToBeAvgd = [\"FGM\", \"FGA\", \"FG_PCT\", \"FG3M\", \"FG3A\", \"FTM\", \"FTA\", \"FT_PCT\",\n",
        "                     \"OREB\", \"DREB\", \"REB\" , \"AST\", \"STL\", \"BLK\", \"TOV\", \"PF\", \"PTS\"]\n",
        "\n",
        "    # average the stats from n-1 most recent games\n",
        "    avgStatsOne = teamStatsOne.loc[1:num_games-1, statsToBeAvgd].mean().to_frame().T\n",
        "\n",
        "    # rename the PTS column to AVG_PTS\n",
        "    avgStatsOne = avgStatsOne.rename(columns={\"PTS\": \"AVG_PTS\"})\n",
        "\n",
        "    # get additional stats\n",
        "    gameIdOne = teamStatsOne.loc[1:num_games-1, \"Game_ID\"]\n",
        "\n",
        "    temp1 = pd.DataFrame()\n",
        "\n",
        "    for gameId in gameIdOne:\n",
        "      time.sleep(0.5)\n",
        "      temp1 = pd.concat([temp1, boxscoreadvancedv2.BoxScoreAdvancedV2(game_id=gameId).get_data_frames()[1]], ignore_index=True)\n",
        "\n",
        "    moreTeamStatsOne = temp1[temp1[\"TEAM_NAME\"].str.lower() == teamOne.split(\" \")[1]]\n",
        "\n",
        "    moreStatsTobeAvgd = ['E_OFF_RATING', 'OFF_RATING', 'E_DEF_RATING', 'DEF_RATING',\n",
        "                         'E_NET_RATING', 'NET_RATING', 'AST_PCT', 'AST_TOV', 'AST_RATIO',\n",
        "                         'OREB_PCT', 'DREB_PCT', 'REB_PCT', 'E_TM_TOV_PCT', 'TM_TOV_PCT',\n",
        "                         'EFG_PCT', 'TS_PCT', 'USG_PCT', 'E_USG_PCT', 'E_PACE', 'PACE',\n",
        "                         'PACE_PER40', 'POSS', 'PIE']\n",
        "\n",
        "    moreStatsAvgOne = moreTeamStatsOne.loc[:, moreStatsTobeAvgd].mean().to_frame().T\n",
        "\n",
        "    # concatenates the two df's of stats\n",
        "    avgStatsOne = pd.concat([avgStatsOne, moreStatsAvgOne], axis = 1)\n",
        "\n",
        "    # adds target to dataframe, points scored in the most recent game\n",
        "    scoreOne = teamStatsOne.loc[0, \"PTS\"]\n",
        "    avgStatsOne[\"TARGET\"] = scoreOne\n",
        "\n",
        "    return avgStatsOne\n",
        "\n",
        "data = pd.DataFrame()\n",
        "for team in team_dict.keys():\n",
        "    team_data = getRecentGames(team)\n",
        "    data = pd.concat([data, team_data], axis=0, ignore_index=True)\n",
        "    #time.sleep(3)\n",
        "    #print(data)\n"
      ],
      "metadata": {
        "id": "SQ0RPJd_2dpo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('/content/drive/My Drive/NBADATA.csv', index=False)"
      ],
      "metadata": {
        "id": "cv2HCnfhliEQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/NBADATA.csv')\n",
        "y = df.pop(\"TARGET\")\n",
        "X = df\n",
        "\n",
        "# impute medians\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "# scale data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
        "\n",
        "# save scaler\n",
        "joblib.dump(scaler, \"/content/drive/My Drive/NBA_scaler.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYoIbr2kmAjn",
        "outputId": "5a741243-3953-4d4e-f0f3-6cad0e7924d2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/NBA_scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "2Iu8Dzpxth2f"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "val_mae_scores = []\n",
        "\n",
        "for train_index, val_index in kf.split(X_scaled):\n",
        "\n",
        "    # split data\n",
        "    X_train, X_val = X_scaled.iloc[train_index], X_scaled.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # build and train\n",
        "    model = build_model(input_shape=X_train.shape[1])\n",
        "    history = model.fit(X_train, y_train, epochs=150, batch_size=8,\n",
        "                        validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "    # evaluate\n",
        "    val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
        "    val_mae_scores.append(val_mae)\n",
        "\n",
        "    print(f\"Fold {fold} - Validation MAE: {val_mae:.4f}\")\n",
        "    fold += 1\n",
        "\n",
        "# avg validation MAE\n",
        "print(f\"\\nAverage Validation MAE: {sum(val_mae_scores) / len(val_mae_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1CDgcxitgwE",
        "outputId": "c468ffcb-8cc6-4f2a-c27c-1c328f0edbd6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 244ms/step - loss: 13780.7900 - mae: 116.6383 - val_loss: 13412.6221 - val_mae: 115.1202\n",
            "Epoch 2/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13494.6465 - mae: 115.5456 - val_loss: 13364.4854 - val_mae: 114.9031\n",
            "Epoch 3/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13740.8096 - mae: 116.6086 - val_loss: 13312.4961 - val_mae: 114.6682\n",
            "Epoch 4/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 13734.8213 - mae: 116.4566 - val_loss: 13254.4092 - val_mae: 114.4060\n",
            "Epoch 5/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 13349.6836 - mae: 114.8726 - val_loss: 13188.6943 - val_mae: 114.1092\n",
            "Epoch 6/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 13052.7676 - mae: 113.6043 - val_loss: 13114.4346 - val_mae: 113.7728\n",
            "Epoch 7/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 13238.9141 - mae: 114.4421 - val_loss: 13031.4072 - val_mae: 113.3951\n",
            "Epoch 8/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 13407.6113 - mae: 115.0964 - val_loss: 12938.9482 - val_mae: 112.9730\n",
            "Epoch 9/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 13041.6973 - mae: 113.5464 - val_loss: 12835.2549 - val_mae: 112.4976\n",
            "Epoch 10/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 13279.8916 - mae: 114.4387 - val_loss: 12717.1592 - val_mae: 111.9517\n",
            "Epoch 11/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 12732.5410 - mae: 111.8087 - val_loss: 12582.1875 - val_mae: 111.3232\n",
            "Epoch 12/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 12832.5195 - mae: 112.5765 - val_loss: 12429.5967 - val_mae: 110.6077\n",
            "Epoch 13/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 12586.4971 - mae: 111.3666 - val_loss: 12258.8311 - val_mae: 109.7987\n",
            "Epoch 14/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 12002.8203 - mae: 108.7704 - val_loss: 12065.8994 - val_mae: 108.8763\n",
            "Epoch 15/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 11472.7393 - mae: 106.0689 - val_loss: 11841.8916 - val_mae: 107.7974\n",
            "Epoch 16/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 10711.4453 - mae: 102.3838 - val_loss: 11582.3828 - val_mae: 106.5384\n",
            "Epoch 17/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 10760.7812 - mae: 102.6448 - val_loss: 11290.9092 - val_mae: 105.1043\n",
            "Epoch 18/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 10531.4209 - mae: 101.3129 - val_loss: 10963.9678 - val_mae: 103.4666\n",
            "Epoch 19/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9865.5830 - mae: 97.9716 - val_loss: 10597.3252 - val_mae: 101.6016\n",
            "Epoch 20/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9650.5820 - mae: 96.6332 - val_loss: 10194.5430 - val_mae: 99.5007\n",
            "Epoch 21/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 9209.6416 - mae: 94.2626 - val_loss: 9747.7695 - val_mae: 97.1117\n",
            "Epoch 22/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8903.7031 - mae: 92.5784 - val_loss: 9262.5088 - val_mae: 94.4353\n",
            "Epoch 23/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7996.5181 - mae: 87.2386 - val_loss: 8735.0566 - val_mae: 91.4240\n",
            "Epoch 24/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7047.8750 - mae: 81.2618 - val_loss: 8177.2715 - val_mae: 88.0963\n",
            "Epoch 25/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6418.1362 - mae: 76.3922 - val_loss: 7589.2798 - val_mae: 84.4269\n",
            "Epoch 26/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5420.1289 - mae: 70.0258 - val_loss: 6983.3296 - val_mae: 80.4244\n",
            "Epoch 27/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4401.7378 - mae: 61.3773 - val_loss: 6375.5444 - val_mae: 76.1578\n",
            "Epoch 28/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4187.0986 - mae: 58.9836 - val_loss: 5771.1035 - val_mae: 71.5990\n",
            "Epoch 29/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3737.3813 - mae: 55.5262 - val_loss: 5198.7388 - val_mae: 66.9003\n",
            "Epoch 30/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2979.1084 - mae: 48.8060 - val_loss: 4673.2944 - val_mae: 62.1888\n",
            "Epoch 31/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2632.9363 - mae: 43.4782 - val_loss: 4208.4839 - val_mae: 57.5969\n",
            "Epoch 32/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2372.7273 - mae: 39.9745 - val_loss: 3802.6208 - val_mae: 53.0976\n",
            "Epoch 33/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2003.4241 - mae: 37.8455 - val_loss: 3498.6794 - val_mae: 49.3047\n",
            "Epoch 34/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1990.6506 - mae: 36.9509 - val_loss: 3256.1416 - val_mae: 45.9040\n",
            "Epoch 35/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1562.7028 - mae: 31.8077 - val_loss: 3084.8586 - val_mae: 44.2343\n",
            "Epoch 36/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1686.6853 - mae: 34.3140 - val_loss: 2979.4338 - val_mae: 43.2798\n",
            "Epoch 37/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1448.7794 - mae: 31.2870 - val_loss: 2912.6980 - val_mae: 42.5401\n",
            "Epoch 38/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1429.4874 - mae: 31.7271 - val_loss: 2877.3584 - val_mae: 42.2212\n",
            "Epoch 39/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1280.4352 - mae: 29.3822 - val_loss: 2846.7285 - val_mae: 41.9046\n",
            "Epoch 40/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1196.2466 - mae: 28.7616 - val_loss: 2830.5618 - val_mae: 41.8440\n",
            "Epoch 41/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1089.3987 - mae: 27.1711 - val_loss: 2816.9597 - val_mae: 41.6974\n",
            "Epoch 42/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 800.4183 - mae: 22.7503 - val_loss: 2801.8958 - val_mae: 41.6096\n",
            "Epoch 43/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 934.3513 - mae: 24.4996 - val_loss: 2781.8474 - val_mae: 41.4814\n",
            "Epoch 44/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 874.3030 - mae: 24.0666 - val_loss: 2764.7268 - val_mae: 41.5688\n",
            "Epoch 45/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 823.7895 - mae: 23.2875 - val_loss: 2739.4558 - val_mae: 41.6395\n",
            "Epoch 46/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 616.8900 - mae: 19.8766 - val_loss: 2711.2744 - val_mae: 41.6905\n",
            "Epoch 47/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 715.0845 - mae: 22.3903 - val_loss: 2684.2913 - val_mae: 41.7139\n",
            "Epoch 48/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 786.3319 - mae: 23.3349 - val_loss: 2645.0334 - val_mae: 41.7586\n",
            "Epoch 49/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 692.0744 - mae: 22.2333 - val_loss: 2620.1597 - val_mae: 41.7929\n",
            "Epoch 50/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 596.3908 - mae: 20.8979 - val_loss: 2590.4045 - val_mae: 41.8350\n",
            "Epoch 51/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 552.4192 - mae: 19.8503 - val_loss: 2567.2329 - val_mae: 41.8759\n",
            "Epoch 52/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 493.4698 - mae: 19.1194 - val_loss: 2539.6301 - val_mae: 41.9434\n",
            "Epoch 53/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 447.1654 - mae: 17.8717 - val_loss: 2520.0144 - val_mae: 41.9886\n",
            "Epoch 54/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 499.9147 - mae: 19.1126 - val_loss: 2497.5208 - val_mae: 42.0337\n",
            "Epoch 55/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 407.1853 - mae: 17.1822 - val_loss: 2478.6165 - val_mae: 42.0894\n",
            "Epoch 56/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 415.6639 - mae: 17.9959 - val_loss: 2466.1484 - val_mae: 42.1063\n",
            "Epoch 57/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 380.1847 - mae: 17.0996 - val_loss: 2450.4270 - val_mae: 42.1010\n",
            "Epoch 58/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 347.1650 - mae: 16.1292 - val_loss: 2440.6143 - val_mae: 42.1389\n",
            "Epoch 59/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 395.7125 - mae: 16.9420 - val_loss: 2425.0681 - val_mae: 42.1292\n",
            "Epoch 60/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 278.2520 - mae: 14.1476 - val_loss: 2414.7136 - val_mae: 42.1511\n",
            "Epoch 61/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 374.1034 - mae: 16.7933 - val_loss: 2397.2253 - val_mae: 42.1572\n",
            "Epoch 62/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 317.0042 - mae: 15.4077 - val_loss: 2386.4143 - val_mae: 42.1408\n",
            "Epoch 63/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 280.9942 - mae: 14.4992 - val_loss: 2376.7810 - val_mae: 42.1297\n",
            "Epoch 64/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 217.9911 - mae: 12.4537 - val_loss: 2372.7932 - val_mae: 42.1053\n",
            "Epoch 65/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 244.9169 - mae: 13.4441 - val_loss: 2365.5320 - val_mae: 42.0664\n",
            "Epoch 66/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 181.5548 - mae: 11.4577 - val_loss: 2354.4949 - val_mae: 42.0291\n",
            "Epoch 67/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 228.7520 - mae: 12.7118 - val_loss: 2340.7610 - val_mae: 41.9629\n",
            "Epoch 68/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 210.6456 - mae: 12.0316 - val_loss: 2327.1799 - val_mae: 41.8933\n",
            "Epoch 69/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 184.2348 - mae: 11.3817 - val_loss: 2315.7244 - val_mae: 41.7815\n",
            "Epoch 70/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 174.1126 - mae: 11.0962 - val_loss: 2304.5950 - val_mae: 41.6834\n",
            "Epoch 71/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 144.3100 - mae: 9.6941 - val_loss: 2295.1196 - val_mae: 41.5819\n",
            "Epoch 72/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 188.7620 - mae: 11.4838 - val_loss: 2283.1367 - val_mae: 41.4692\n",
            "Epoch 73/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 153.0848 - mae: 10.6038 - val_loss: 2268.8206 - val_mae: 41.3696\n",
            "Epoch 74/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 172.4357 - mae: 11.1219 - val_loss: 2256.0774 - val_mae: 41.2568\n",
            "Epoch 75/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 134.3597 - mae: 9.8350 - val_loss: 2245.5762 - val_mae: 41.1642\n",
            "Epoch 76/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 132.4802 - mae: 9.2956 - val_loss: 2232.8665 - val_mae: 41.0433\n",
            "Epoch 77/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 122.5860 - mae: 8.9639 - val_loss: 2221.0886 - val_mae: 40.9214\n",
            "Epoch 78/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 79.9262 - mae: 7.1866 - val_loss: 2216.5979 - val_mae: 40.8419\n",
            "Epoch 79/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 99.6895 - mae: 8.2532 - val_loss: 2209.6028 - val_mae: 40.7523\n",
            "Epoch 80/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 114.5666 - mae: 8.6045 - val_loss: 2199.3152 - val_mae: 40.6373\n",
            "Epoch 81/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 86.6762 - mae: 7.5412 - val_loss: 2187.7351 - val_mae: 40.5036\n",
            "Epoch 82/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 78.2049 - mae: 7.3764 - val_loss: 2180.2712 - val_mae: 40.4194\n",
            "Epoch 83/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 75.7060 - mae: 7.0876 - val_loss: 2171.6914 - val_mae: 40.3138\n",
            "Epoch 84/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 78.7306 - mae: 7.3650 - val_loss: 2164.2358 - val_mae: 40.2121\n",
            "Epoch 85/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 66.9844 - mae: 6.9094 - val_loss: 2157.4333 - val_mae: 40.1296\n",
            "Epoch 86/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 52.8199 - mae: 6.2444 - val_loss: 2152.7493 - val_mae: 40.0502\n",
            "Epoch 87/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 52.4377 - mae: 6.1936 - val_loss: 2146.3381 - val_mae: 39.9786\n",
            "Epoch 88/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 48.5373 - mae: 5.9184 - val_loss: 2139.7380 - val_mae: 39.8723\n",
            "Epoch 89/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 68.5154 - mae: 6.9468 - val_loss: 2133.3950 - val_mae: 39.7788\n",
            "Epoch 90/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 50.7223 - mae: 6.0509 - val_loss: 2127.8208 - val_mae: 39.6750\n",
            "Epoch 91/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 54.2011 - mae: 6.0947 - val_loss: 2122.9727 - val_mae: 39.5748\n",
            "Epoch 92/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 45.9468 - mae: 5.7062 - val_loss: 2116.9858 - val_mae: 39.4968\n",
            "Epoch 93/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 35.7547 - mae: 4.9606 - val_loss: 2112.1982 - val_mae: 39.4082\n",
            "Epoch 94/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 37.6440 - mae: 5.2483 - val_loss: 2109.3652 - val_mae: 39.3419\n",
            "Epoch 95/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 32.7771 - mae: 4.9870 - val_loss: 2104.8616 - val_mae: 39.2675\n",
            "Epoch 96/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 30.7133 - mae: 4.7733 - val_loss: 2100.5042 - val_mae: 39.2023\n",
            "Epoch 97/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 31.9918 - mae: 4.5268 - val_loss: 2096.6475 - val_mae: 39.1329\n",
            "Epoch 98/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 33.7557 - mae: 4.7294 - val_loss: 2091.0476 - val_mae: 39.0493\n",
            "Epoch 99/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 32.1420 - mae: 4.8350 - val_loss: 2086.6089 - val_mae: 38.9556\n",
            "Epoch 100/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 28.9742 - mae: 4.4522 - val_loss: 2084.0144 - val_mae: 38.8841\n",
            "Epoch 101/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 26.7141 - mae: 4.2556 - val_loss: 2082.6394 - val_mae: 38.8156\n",
            "Epoch 102/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 20.3061 - mae: 3.8007 - val_loss: 2082.5703 - val_mae: 38.7685\n",
            "Epoch 103/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 25.9389 - mae: 4.2508 - val_loss: 2079.9446 - val_mae: 38.7042\n",
            "Epoch 104/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 20.0891 - mae: 3.8026 - val_loss: 2077.4836 - val_mae: 38.6414\n",
            "Epoch 105/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 15.6624 - mae: 3.3387 - val_loss: 2075.5491 - val_mae: 38.5827\n",
            "Epoch 106/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 20.5555 - mae: 3.7354 - val_loss: 2072.2034 - val_mae: 38.5151\n",
            "Epoch 107/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 15.3366 - mae: 3.3159 - val_loss: 2070.1985 - val_mae: 38.4744\n",
            "Epoch 108/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 15.7341 - mae: 3.4112 - val_loss: 2066.3528 - val_mae: 38.4162\n",
            "Epoch 109/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 14.0173 - mae: 3.2654 - val_loss: 2063.5393 - val_mae: 38.3707\n",
            "Epoch 110/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 13.0425 - mae: 3.0844 - val_loss: 2061.5969 - val_mae: 38.3309\n",
            "Epoch 111/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 14.1670 - mae: 3.1595 - val_loss: 2059.4451 - val_mae: 38.2744\n",
            "Epoch 112/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 13.8549 - mae: 3.1301 - val_loss: 2057.8953 - val_mae: 38.2265\n",
            "Epoch 113/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 12.5257 - mae: 2.9452 - val_loss: 2057.1047 - val_mae: 38.1822\n",
            "Epoch 114/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 11.7806 - mae: 2.8262 - val_loss: 2055.5930 - val_mae: 38.1426\n",
            "Epoch 115/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 8.3036 - mae: 2.4478 - val_loss: 2054.6643 - val_mae: 38.0990\n",
            "Epoch 116/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 8.3437 - mae: 2.5013 - val_loss: 2053.1045 - val_mae: 38.0662\n",
            "Epoch 117/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 8.5605 - mae: 2.3859 - val_loss: 2050.5076 - val_mae: 38.0293\n",
            "Epoch 118/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 8.3270 - mae: 2.4952 - val_loss: 2049.7683 - val_mae: 38.0057\n",
            "Epoch 119/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 7.8639 - mae: 2.3505 - val_loss: 2049.2058 - val_mae: 37.9739\n",
            "Epoch 120/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 7.1177 - mae: 2.1894 - val_loss: 2047.8888 - val_mae: 37.9309\n",
            "Epoch 121/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 6.9850 - mae: 2.1961 - val_loss: 2047.7177 - val_mae: 37.8839\n",
            "Epoch 122/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.5231 - mae: 1.9611 - val_loss: 2047.2266 - val_mae: 37.8535\n",
            "Epoch 123/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.7264 - mae: 2.1152 - val_loss: 2047.0137 - val_mae: 37.8281\n",
            "Epoch 124/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.4702 - mae: 1.9874 - val_loss: 2047.2233 - val_mae: 37.8015\n",
            "Epoch 125/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.0641 - mae: 1.8793 - val_loss: 2046.7207 - val_mae: 37.7763\n",
            "Epoch 126/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.0653 - mae: 1.7412 - val_loss: 2046.7681 - val_mae: 37.7566\n",
            "Epoch 127/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.4022 - mae: 1.4801 - val_loss: 2045.3032 - val_mae: 37.7310\n",
            "Epoch 128/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.8726 - mae: 1.6102 - val_loss: 2044.1782 - val_mae: 37.7061\n",
            "Epoch 129/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.3694 - mae: 1.5391 - val_loss: 2042.7614 - val_mae: 37.6878\n",
            "Epoch 130/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.8498 - mae: 1.6274 - val_loss: 2041.0732 - val_mae: 37.6515\n",
            "Epoch 131/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.0146 - mae: 1.4079 - val_loss: 2041.8540 - val_mae: 37.6413\n",
            "Epoch 132/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.8682 - mae: 1.3920 - val_loss: 2042.2941 - val_mae: 37.6246\n",
            "Epoch 133/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.7761 - mae: 1.3783 - val_loss: 2042.6351 - val_mae: 37.6039\n",
            "Epoch 134/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.3418 - mae: 1.2009 - val_loss: 2042.0420 - val_mae: 37.5840\n",
            "Epoch 135/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.1881 - mae: 1.2111 - val_loss: 2041.9772 - val_mae: 37.5668\n",
            "Epoch 136/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.8807 - mae: 1.1175 - val_loss: 2041.6978 - val_mae: 37.5448\n",
            "Epoch 137/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.5303 - mae: 0.9670 - val_loss: 2041.9659 - val_mae: 37.5329\n",
            "Epoch 138/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.9732 - mae: 1.1280 - val_loss: 2041.7101 - val_mae: 37.5167\n",
            "Epoch 139/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.1732 - mae: 1.1777 - val_loss: 2040.7617 - val_mae: 37.4980\n",
            "Epoch 140/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.6328 - mae: 1.0381 - val_loss: 2041.1495 - val_mae: 37.4846\n",
            "Epoch 141/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.4196 - mae: 0.9824 - val_loss: 2041.0273 - val_mae: 37.4705\n",
            "Epoch 142/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.6639 - mae: 1.0208 - val_loss: 2040.5480 - val_mae: 37.4546\n",
            "Epoch 143/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.8348 - mae: 1.0937 - val_loss: 2040.3632 - val_mae: 37.4436\n",
            "Epoch 144/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0924 - mae: 0.8014 - val_loss: 2040.6543 - val_mae: 37.4358\n",
            "Epoch 145/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.2644 - mae: 0.8730 - val_loss: 2040.4962 - val_mae: 37.4239\n",
            "Epoch 146/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2810 - mae: 0.8978 - val_loss: 2040.7184 - val_mae: 37.4135\n",
            "Epoch 147/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.2807 - mae: 0.9289 - val_loss: 2040.7047 - val_mae: 37.3992\n",
            "Epoch 148/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.0062 - mae: 0.7867 - val_loss: 2041.2467 - val_mae: 37.3919\n",
            "Epoch 149/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.8958 - mae: 0.7151 - val_loss: 2040.9989 - val_mae: 37.3823\n",
            "Epoch 150/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.8575 - mae: 0.7198 - val_loss: 2041.1461 - val_mae: 37.3692\n",
            "Fold 1 - Validation MAE: 37.3692\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - loss: 14209.3965 - mae: 118.5175 - val_loss: 13634.4092 - val_mae: 115.8009\n",
            "Epoch 2/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 13400.2373 - mae: 115.1447 - val_loss: 13605.3623 - val_mae: 115.6746\n",
            "Epoch 3/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 14076.4326 - mae: 117.9291 - val_loss: 13578.6914 - val_mae: 115.5567\n",
            "Epoch 4/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13488.4072 - mae: 115.5114 - val_loss: 13549.8135 - val_mae: 115.4284\n",
            "Epoch 5/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13759.6396 - mae: 116.5474 - val_loss: 13519.3916 - val_mae: 115.2924\n",
            "Epoch 6/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 14114.5352 - mae: 118.2201 - val_loss: 13486.9678 - val_mae: 115.1481\n",
            "Epoch 7/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13905.0742 - mae: 117.2194 - val_loss: 13451.1133 - val_mae: 114.9923\n",
            "Epoch 8/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 13689.5264 - mae: 116.2692 - val_loss: 13412.5830 - val_mae: 114.8247\n",
            "Epoch 9/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 13530.3564 - mae: 115.6236 - val_loss: 13369.3662 - val_mae: 114.6364\n",
            "Epoch 10/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13981.6885 - mae: 117.5390 - val_loss: 13319.6104 - val_mae: 114.4193\n",
            "Epoch 11/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13220.4766 - mae: 114.2413 - val_loss: 13262.5166 - val_mae: 114.1691\n",
            "Epoch 12/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13431.3975 - mae: 115.1647 - val_loss: 13198.3428 - val_mae: 113.8875\n",
            "Epoch 13/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13468.1289 - mae: 115.3513 - val_loss: 13126.6514 - val_mae: 113.5724\n",
            "Epoch 14/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13439.5293 - mae: 115.2465 - val_loss: 13044.7393 - val_mae: 113.2116\n",
            "Epoch 15/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 12894.2070 - mae: 112.8628 - val_loss: 12953.4102 - val_mae: 112.8074\n",
            "Epoch 16/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 13065.3789 - mae: 113.5945 - val_loss: 12847.9736 - val_mae: 112.3409\n",
            "Epoch 17/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 12585.8027 - mae: 111.5185 - val_loss: 12733.5625 - val_mae: 111.8314\n",
            "Epoch 18/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 12965.4414 - mae: 113.1391 - val_loss: 12605.7773 - val_mae: 111.2613\n",
            "Epoch 19/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 12495.7227 - mae: 110.8899 - val_loss: 12466.3701 - val_mae: 110.6353\n",
            "Epoch 20/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 12475.5469 - mae: 110.8936 - val_loss: 12308.2588 - val_mae: 109.9211\n",
            "Epoch 21/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 12411.5078 - mae: 110.5452 - val_loss: 12129.5830 - val_mae: 109.1088\n",
            "Epoch 22/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 11495.5938 - mae: 106.2999 - val_loss: 11932.2578 - val_mae: 108.2038\n",
            "Epoch 23/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 11401.3701 - mae: 105.7923 - val_loss: 11714.6436 - val_mae: 107.1967\n",
            "Epoch 24/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10731.0195 - mae: 102.3937 - val_loss: 11474.2588 - val_mae: 106.0768\n",
            "Epoch 25/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 10453.7500 - mae: 101.0174 - val_loss: 11212.1143 - val_mae: 104.8362\n",
            "Epoch 26/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 10434.1045 - mae: 100.8974 - val_loss: 10919.9814 - val_mae: 103.4374\n",
            "Epoch 27/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 9714.4854 - mae: 97.1769 - val_loss: 10599.8438 - val_mae: 101.8810\n",
            "Epoch 28/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8667.0254 - mae: 91.3901 - val_loss: 10253.1455 - val_mae: 100.1640\n",
            "Epoch 29/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9028.7461 - mae: 92.7908 - val_loss: 9882.6748 - val_mae: 98.2956\n",
            "Epoch 30/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7867.2925 - mae: 85.8171 - val_loss: 9475.8057 - val_mae: 96.2026\n",
            "Epoch 31/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7421.7817 - mae: 82.6757 - val_loss: 9043.1436 - val_mae: 93.9162\n",
            "Epoch 32/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6711.9180 - mae: 78.2563 - val_loss: 8583.1162 - val_mae: 91.4216\n",
            "Epoch 33/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 6069.0703 - mae: 72.9258 - val_loss: 8096.1216 - val_mae: 88.7021\n",
            "Epoch 34/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5041.6851 - mae: 64.7434 - val_loss: 7594.0898 - val_mae: 85.7974\n",
            "Epoch 35/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5245.0903 - mae: 64.9997 - val_loss: 7065.5391 - val_mae: 82.6326\n",
            "Epoch 36/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4499.2085 - mae: 57.9245 - val_loss: 6534.3550 - val_mae: 79.3137\n",
            "Epoch 37/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3768.4714 - mae: 49.4299 - val_loss: 6011.2227 - val_mae: 75.8894\n",
            "Epoch 38/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3550.2090 - mae: 48.7052 - val_loss: 5485.8540 - val_mae: 72.2835\n",
            "Epoch 39/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3079.8105 - mae: 47.0343 - val_loss: 4976.0532 - val_mae: 68.5963\n",
            "Epoch 40/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3231.9663 - mae: 48.4792 - val_loss: 4501.5542 - val_mae: 64.9895\n",
            "Epoch 41/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2820.3936 - mae: 46.0665 - val_loss: 4046.7000 - val_mae: 61.3271\n",
            "Epoch 42/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 2307.3875 - mae: 41.1207 - val_loss: 3667.6121 - val_mae: 58.1079\n",
            "Epoch 43/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2347.7283 - mae: 41.1579 - val_loss: 3340.2224 - val_mae: 55.1982\n",
            "Epoch 44/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2199.0391 - mae: 39.6882 - val_loss: 3057.1086 - val_mae: 52.5498\n",
            "Epoch 45/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2053.2063 - mae: 38.9274 - val_loss: 2807.2356 - val_mae: 50.1233\n",
            "Epoch 46/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1923.3584 - mae: 36.6015 - val_loss: 2590.1318 - val_mae: 47.9081\n",
            "Epoch 47/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2072.0518 - mae: 38.0158 - val_loss: 2407.6497 - val_mae: 45.9302\n",
            "Epoch 48/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2137.4661 - mae: 38.8492 - val_loss: 2265.6960 - val_mae: 44.3265\n",
            "Epoch 49/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1859.7175 - mae: 36.2973 - val_loss: 2131.9480 - val_mae: 42.7344\n",
            "Epoch 50/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1343.9261 - mae: 29.5248 - val_loss: 2026.4103 - val_mae: 41.3869\n",
            "Epoch 51/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1544.9800 - mae: 32.8144 - val_loss: 1892.8539 - val_mae: 39.6083\n",
            "Epoch 52/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1299.3217 - mae: 29.3189 - val_loss: 1783.8654 - val_mae: 38.0630\n",
            "Epoch 53/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1460.4760 - mae: 31.4917 - val_loss: 1706.5815 - val_mae: 36.8439\n",
            "Epoch 54/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1218.7592 - mae: 26.8740 - val_loss: 1617.8853 - val_mae: 35.3946\n",
            "Epoch 55/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1079.6455 - mae: 25.2321 - val_loss: 1537.1010 - val_mae: 33.9873\n",
            "Epoch 56/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1040.5555 - mae: 25.6993 - val_loss: 1468.4185 - val_mae: 32.6779\n",
            "Epoch 57/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 716.2619 - mae: 20.1408 - val_loss: 1418.3336 - val_mae: 31.6295\n",
            "Epoch 58/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 704.1130 - mae: 20.4499 - val_loss: 1359.6271 - val_mae: 30.3772\n",
            "Epoch 59/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 793.5675 - mae: 23.3034 - val_loss: 1313.7803 - val_mae: 29.3084\n",
            "Epoch 60/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 708.9995 - mae: 21.5364 - val_loss: 1270.7098 - val_mae: 28.3100\n",
            "Epoch 61/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 808.3099 - mae: 22.4234 - val_loss: 1228.3032 - val_mae: 27.2285\n",
            "Epoch 62/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 813.1285 - mae: 22.6343 - val_loss: 1180.1268 - val_mae: 26.2310\n",
            "Epoch 63/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 635.0134 - mae: 20.6057 - val_loss: 1158.2635 - val_mae: 25.5698\n",
            "Epoch 64/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 613.6575 - mae: 20.1819 - val_loss: 1136.4781 - val_mae: 24.9297\n",
            "Epoch 65/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 584.5439 - mae: 19.6156 - val_loss: 1120.7769 - val_mae: 24.8080\n",
            "Epoch 66/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 453.8542 - mae: 17.5807 - val_loss: 1111.5094 - val_mae: 24.8124\n",
            "Epoch 67/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 528.6812 - mae: 19.0640 - val_loss: 1092.3829 - val_mae: 24.7216\n",
            "Epoch 68/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 480.2238 - mae: 17.9740 - val_loss: 1081.6317 - val_mae: 24.6854\n",
            "Epoch 69/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 449.0902 - mae: 17.4280 - val_loss: 1075.2108 - val_mae: 24.7446\n",
            "Epoch 70/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 384.3674 - mae: 16.1341 - val_loss: 1065.6349 - val_mae: 24.7299\n",
            "Epoch 71/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 380.9440 - mae: 16.5277 - val_loss: 1054.7520 - val_mae: 24.6670\n",
            "Epoch 72/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 422.4642 - mae: 16.9621 - val_loss: 1042.8353 - val_mae: 24.6068\n",
            "Epoch 73/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 375.5017 - mae: 15.9961 - val_loss: 1034.1162 - val_mae: 24.5767\n",
            "Epoch 74/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 364.7365 - mae: 16.1306 - val_loss: 1023.7725 - val_mae: 24.5114\n",
            "Epoch 75/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 270.1358 - mae: 13.8617 - val_loss: 1016.5057 - val_mae: 24.4550\n",
            "Epoch 76/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 274.6630 - mae: 13.7412 - val_loss: 1004.0058 - val_mae: 24.3683\n",
            "Epoch 77/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 280.8220 - mae: 13.8658 - val_loss: 991.9465 - val_mae: 24.5692\n",
            "Epoch 78/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 198.5102 - mae: 11.8944 - val_loss: 985.6628 - val_mae: 24.7437\n",
            "Epoch 79/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 246.2367 - mae: 12.8070 - val_loss: 979.3557 - val_mae: 24.9676\n",
            "Epoch 80/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 195.3456 - mae: 11.2554 - val_loss: 972.7197 - val_mae: 25.1376\n",
            "Epoch 81/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 171.7520 - mae: 10.9314 - val_loss: 967.2336 - val_mae: 25.2875\n",
            "Epoch 82/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 166.7635 - mae: 11.1223 - val_loss: 962.0353 - val_mae: 25.4516\n",
            "Epoch 83/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 169.4046 - mae: 11.0537 - val_loss: 959.8525 - val_mae: 25.6292\n",
            "Epoch 84/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 126.4350 - mae: 9.2796 - val_loss: 957.2971 - val_mae: 25.7740\n",
            "Epoch 85/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 147.1816 - mae: 9.8205 - val_loss: 954.9904 - val_mae: 25.9056\n",
            "Epoch 86/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 128.0730 - mae: 9.5181 - val_loss: 956.3962 - val_mae: 26.0918\n",
            "Epoch 87/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 111.3226 - mae: 8.8001 - val_loss: 956.8979 - val_mae: 26.2676\n",
            "Epoch 88/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 97.1558 - mae: 7.9316 - val_loss: 956.5537 - val_mae: 26.3919\n",
            "Epoch 89/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 122.4568 - mae: 8.7240 - val_loss: 956.0171 - val_mae: 26.5278\n",
            "Epoch 90/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 88.2868 - mae: 7.8227 - val_loss: 957.8698 - val_mae: 26.6413\n",
            "Epoch 91/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 71.8427 - mae: 6.9305 - val_loss: 961.2430 - val_mae: 26.7819\n",
            "Epoch 92/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 84.5473 - mae: 7.3920 - val_loss: 966.6706 - val_mae: 26.9382\n",
            "Epoch 93/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 70.0656 - mae: 6.7604 - val_loss: 971.3135 - val_mae: 27.0626\n",
            "Epoch 94/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 58.4107 - mae: 6.2220 - val_loss: 976.9759 - val_mae: 27.1995\n",
            "Epoch 95/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 63.9708 - mae: 6.7440 - val_loss: 980.6050 - val_mae: 27.2931\n",
            "Epoch 96/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 59.8910 - mae: 6.5277 - val_loss: 985.0301 - val_mae: 27.3928\n",
            "Epoch 97/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 54.7236 - mae: 5.7735 - val_loss: 991.8208 - val_mae: 27.5210\n",
            "Epoch 98/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 50.6987 - mae: 5.5148 - val_loss: 998.1627 - val_mae: 27.6205\n",
            "Epoch 99/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 48.7031 - mae: 5.6919 - val_loss: 1005.5005 - val_mae: 27.7446\n",
            "Epoch 100/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 43.5834 - mae: 5.2570 - val_loss: 1012.5981 - val_mae: 27.8448\n",
            "Epoch 101/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 32.1851 - mae: 4.7100 - val_loss: 1019.4500 - val_mae: 27.9586\n",
            "Epoch 102/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 41.6682 - mae: 5.1839 - val_loss: 1027.1619 - val_mae: 28.0582\n",
            "Epoch 103/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 31.8289 - mae: 4.5390 - val_loss: 1033.3287 - val_mae: 28.1285\n",
            "Epoch 104/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 33.3929 - mae: 4.8581 - val_loss: 1040.0355 - val_mae: 28.1898\n",
            "Epoch 105/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 22.4380 - mae: 3.8747 - val_loss: 1046.1677 - val_mae: 28.2634\n",
            "Epoch 106/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 25.5466 - mae: 4.1198 - val_loss: 1053.3297 - val_mae: 28.3289\n",
            "Epoch 107/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 21.5911 - mae: 3.8002 - val_loss: 1059.9656 - val_mae: 28.3975\n",
            "Epoch 108/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 19.2615 - mae: 3.4250 - val_loss: 1065.5665 - val_mae: 28.4592\n",
            "Epoch 109/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 20.5793 - mae: 3.6799 - val_loss: 1072.3418 - val_mae: 28.5157\n",
            "Epoch 110/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 19.3989 - mae: 3.6006 - val_loss: 1080.0865 - val_mae: 28.5966\n",
            "Epoch 111/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 21.2448 - mae: 3.7094 - val_loss: 1086.5874 - val_mae: 28.6386\n",
            "Epoch 112/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 15.8349 - mae: 3.1443 - val_loss: 1091.8105 - val_mae: 28.6708\n",
            "Epoch 113/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 15.6144 - mae: 3.2272 - val_loss: 1096.8492 - val_mae: 28.7039\n",
            "Epoch 114/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 17.0831 - mae: 3.4287 - val_loss: 1102.4225 - val_mae: 28.7436\n",
            "Epoch 115/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 12.9215 - mae: 2.7624 - val_loss: 1107.7999 - val_mae: 28.7848\n",
            "Epoch 116/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 12.3108 - mae: 2.8298 - val_loss: 1112.3613 - val_mae: 28.8280\n",
            "Epoch 117/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 15.1513 - mae: 3.1860 - val_loss: 1117.7662 - val_mae: 28.8666\n",
            "Epoch 118/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10.5804 - mae: 2.6851 - val_loss: 1122.5662 - val_mae: 28.9078\n",
            "Epoch 119/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 11.3669 - mae: 2.6456 - val_loss: 1126.6466 - val_mae: 28.9349\n",
            "Epoch 120/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.3168 - mae: 2.3390 - val_loss: 1129.9823 - val_mae: 28.9633\n",
            "Epoch 121/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.9765 - mae: 2.5245 - val_loss: 1132.9565 - val_mae: 28.9804\n",
            "Epoch 122/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10.1198 - mae: 2.5379 - val_loss: 1136.6727 - val_mae: 28.9899\n",
            "Epoch 123/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.0420 - mae: 2.0824 - val_loss: 1140.7101 - val_mae: 29.0197\n",
            "Epoch 124/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.1550 - mae: 2.1372 - val_loss: 1144.2303 - val_mae: 29.0376\n",
            "Epoch 125/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.1031 - mae: 2.2437 - val_loss: 1146.6591 - val_mae: 29.0351\n",
            "Epoch 126/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.8736 - mae: 2.0665 - val_loss: 1148.3102 - val_mae: 29.0262\n",
            "Epoch 127/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.2973 - mae: 1.9044 - val_loss: 1150.4869 - val_mae: 29.0518\n",
            "Epoch 128/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.9113 - mae: 1.6879 - val_loss: 1152.7709 - val_mae: 29.0544\n",
            "Epoch 129/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.7140 - mae: 2.0227 - val_loss: 1155.1876 - val_mae: 29.0475\n",
            "Epoch 130/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.9423 - mae: 1.8159 - val_loss: 1157.0890 - val_mae: 29.0572\n",
            "Epoch 131/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.7080 - mae: 1.9992 - val_loss: 1158.9344 - val_mae: 29.0692\n",
            "Epoch 132/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.7102 - mae: 1.7570 - val_loss: 1159.1183 - val_mae: 29.0644\n",
            "Epoch 133/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.5141 - mae: 1.6901 - val_loss: 1160.7852 - val_mae: 29.0658\n",
            "Epoch 134/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 3.7317 - mae: 1.5555 - val_loss: 1162.1304 - val_mae: 29.0689\n",
            "Epoch 135/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.5199 - mae: 1.4915 - val_loss: 1163.0294 - val_mae: 29.0644\n",
            "Epoch 136/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.0242 - mae: 1.3820 - val_loss: 1163.9491 - val_mae: 29.0637\n",
            "Epoch 137/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.0010 - mae: 1.3975 - val_loss: 1164.8895 - val_mae: 29.0662\n",
            "Epoch 138/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.3306 - mae: 1.4691 - val_loss: 1165.6927 - val_mae: 29.0653\n",
            "Epoch 139/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.3057 - mae: 1.4209 - val_loss: 1166.8170 - val_mae: 29.0581\n",
            "Epoch 140/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.3269 - mae: 1.4873 - val_loss: 1167.6528 - val_mae: 29.0468\n",
            "Epoch 141/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.6890 - mae: 1.2527 - val_loss: 1168.5432 - val_mae: 29.0436\n",
            "Epoch 142/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.3174 - mae: 1.3897 - val_loss: 1169.5736 - val_mae: 29.0351\n",
            "Epoch 143/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.0233 - mae: 1.1476 - val_loss: 1170.0862 - val_mae: 29.0374\n",
            "Epoch 144/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.9934 - mae: 1.3095 - val_loss: 1170.4584 - val_mae: 29.0274\n",
            "Epoch 145/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.9063 - mae: 1.0810 - val_loss: 1171.0887 - val_mae: 29.0274\n",
            "Epoch 146/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.7056 - mae: 1.2531 - val_loss: 1171.7299 - val_mae: 29.0305\n",
            "Epoch 147/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.8782 - mae: 1.3423 - val_loss: 1171.4950 - val_mae: 29.0277\n",
            "Epoch 148/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.2890 - mae: 1.1010 - val_loss: 1171.4493 - val_mae: 29.0316\n",
            "Epoch 149/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.4335 - mae: 0.9448 - val_loss: 1171.8519 - val_mae: 29.0335\n",
            "Epoch 150/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.5728 - mae: 0.9585 - val_loss: 1172.0199 - val_mae: 29.0329\n",
            "Fold 2 - Validation MAE: 29.0329\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - loss: 14038.3613 - mae: 117.9930 - val_loss: 14912.4766 - val_mae: 121.3156\n",
            "Epoch 2/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 14152.1592 - mae: 118.2311 - val_loss: 14853.2197 - val_mae: 121.0762\n",
            "Epoch 3/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 13756.6875 - mae: 116.6579 - val_loss: 14800.2295 - val_mae: 120.8617\n",
            "Epoch 4/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13820.9922 - mae: 116.9500 - val_loss: 14751.4365 - val_mae: 120.6620\n",
            "Epoch 5/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13682.3389 - mae: 116.3671 - val_loss: 14703.7734 - val_mae: 120.4653\n",
            "Epoch 6/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13313.5879 - mae: 114.5508 - val_loss: 14654.3486 - val_mae: 120.2610\n",
            "Epoch 7/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13614.4785 - mae: 116.1034 - val_loss: 14601.6260 - val_mae: 120.0419\n",
            "Epoch 8/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 13680.6475 - mae: 116.1967 - val_loss: 14542.0166 - val_mae: 119.7934\n",
            "Epoch 9/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 12965.9990 - mae: 113.1899 - val_loss: 14475.9600 - val_mae: 119.5165\n",
            "Epoch 10/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 12902.7227 - mae: 112.9472 - val_loss: 14404.4844 - val_mae: 119.2171\n",
            "Epoch 11/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13082.5508 - mae: 113.6500 - val_loss: 14323.7266 - val_mae: 118.8783\n",
            "Epoch 12/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 13540.7344 - mae: 115.7516 - val_loss: 14235.3955 - val_mae: 118.5054\n",
            "Epoch 13/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13448.9346 - mae: 115.2606 - val_loss: 14134.7617 - val_mae: 118.0807\n",
            "Epoch 14/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 12688.8672 - mae: 112.0108 - val_loss: 14023.9346 - val_mae: 117.6112\n",
            "Epoch 15/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 12473.5771 - mae: 111.0629 - val_loss: 13898.6123 - val_mae: 117.0777\n",
            "Epoch 16/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 12671.3906 - mae: 111.9624 - val_loss: 13766.0537 - val_mae: 116.5103\n",
            "Epoch 17/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 12869.7109 - mae: 112.7253 - val_loss: 13624.0088 - val_mae: 115.8984\n",
            "Epoch 18/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 12627.7695 - mae: 111.4149 - val_loss: 13469.4248 - val_mae: 115.2272\n",
            "Epoch 19/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 12100.2266 - mae: 109.0658 - val_loss: 13298.7842 - val_mae: 114.4827\n",
            "Epoch 20/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 11687.0293 - mae: 107.1103 - val_loss: 13119.5654 - val_mae: 113.6942\n",
            "Epoch 21/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 11740.8799 - mae: 107.3731 - val_loss: 12926.5430 - val_mae: 112.8382\n",
            "Epoch 22/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 11231.7949 - mae: 104.7795 - val_loss: 12713.8291 - val_mae: 111.8890\n",
            "Epoch 23/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 10819.8516 - mae: 102.8090 - val_loss: 12485.9502 - val_mae: 110.8605\n",
            "Epoch 24/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10552.3848 - mae: 101.2954 - val_loss: 12239.4102 - val_mae: 109.7360\n",
            "Epoch 25/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9668.4453 - mae: 96.6131 - val_loss: 11978.2783 - val_mae: 108.5317\n",
            "Epoch 26/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9987.8281 - mae: 98.6072 - val_loss: 11693.5820 - val_mae: 107.2042\n",
            "Epoch 27/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9434.2334 - mae: 95.4140 - val_loss: 11385.9766 - val_mae: 105.7473\n",
            "Epoch 28/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 9149.7549 - mae: 93.9181 - val_loss: 11064.3096 - val_mae: 104.2016\n",
            "Epoch 29/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8550.8125 - mae: 90.2641 - val_loss: 10720.1318 - val_mae: 102.5196\n",
            "Epoch 30/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7857.5981 - mae: 85.9670 - val_loss: 10360.8350 - val_mae: 100.7322\n",
            "Epoch 31/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7322.4204 - mae: 82.3512 - val_loss: 9982.9297 - val_mae: 98.8113\n",
            "Epoch 32/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7140.1279 - mae: 79.7244 - val_loss: 9594.6094 - val_mae: 96.7940\n",
            "Epoch 33/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6281.0317 - mae: 75.3856 - val_loss: 9191.2217 - val_mae: 94.6392\n",
            "Epoch 34/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6156.6665 - mae: 74.8712 - val_loss: 8764.9990 - val_mae: 92.3046\n",
            "Epoch 35/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4955.1230 - mae: 66.0201 - val_loss: 8338.7041 - val_mae: 89.8931\n",
            "Epoch 36/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4423.0566 - mae: 61.6472 - val_loss: 7898.9019 - val_mae: 87.3226\n",
            "Epoch 37/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4371.5688 - mae: 60.3970 - val_loss: 7437.2886 - val_mae: 84.5351\n",
            "Epoch 38/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3743.4900 - mae: 55.3235 - val_loss: 6990.8940 - val_mae: 81.7234\n",
            "Epoch 39/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2830.2366 - mae: 46.4396 - val_loss: 6538.8022 - val_mae: 78.7494\n",
            "Epoch 40/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2957.4033 - mae: 43.7223 - val_loss: 6092.9980 - val_mae: 75.6877\n",
            "Epoch 41/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2543.3738 - mae: 39.8568 - val_loss: 5684.7539 - val_mae: 72.7280\n",
            "Epoch 42/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2553.1160 - mae: 40.5660 - val_loss: 5298.9507 - val_mae: 69.8036\n",
            "Epoch 43/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2043.5251 - mae: 36.7031 - val_loss: 4924.6616 - val_mae: 66.8325\n",
            "Epoch 44/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1950.7416 - mae: 35.2570 - val_loss: 4578.3228 - val_mae: 63.9342\n",
            "Epoch 45/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2028.5229 - mae: 36.1810 - val_loss: 4288.5366 - val_mae: 61.3401\n",
            "Epoch 46/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1800.9375 - mae: 34.7236 - val_loss: 4030.2893 - val_mae: 58.9295\n",
            "Epoch 47/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1295.7638 - mae: 28.3480 - val_loss: 3825.9580 - val_mae: 56.9414\n",
            "Epoch 48/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1666.1179 - mae: 32.4744 - val_loss: 3621.8865 - val_mae: 54.9079\n",
            "Epoch 49/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1840.1661 - mae: 34.0407 - val_loss: 3443.2820 - val_mae: 53.0875\n",
            "Epoch 50/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1684.6213 - mae: 33.9322 - val_loss: 3297.6406 - val_mae: 52.1250\n",
            "Epoch 51/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1459.9745 - mae: 30.4993 - val_loss: 3159.8242 - val_mae: 51.4066\n",
            "Epoch 52/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1094.9609 - mae: 24.9059 - val_loss: 3041.5164 - val_mae: 50.7134\n",
            "Epoch 53/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1168.0200 - mae: 26.8087 - val_loss: 2917.1243 - val_mae: 49.8788\n",
            "Epoch 54/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1098.5020 - mae: 26.5773 - val_loss: 2801.8711 - val_mae: 49.0327\n",
            "Epoch 55/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1145.0603 - mae: 27.6538 - val_loss: 2683.7190 - val_mae: 48.1664\n",
            "Epoch 56/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 856.5341 - mae: 23.3128 - val_loss: 2587.3030 - val_mae: 47.3909\n",
            "Epoch 57/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 964.5262 - mae: 24.5023 - val_loss: 2486.7104 - val_mae: 46.5293\n",
            "Epoch 58/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 803.1556 - mae: 22.7812 - val_loss: 2397.3054 - val_mae: 45.7729\n",
            "Epoch 59/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 917.7398 - mae: 24.9879 - val_loss: 2295.1536 - val_mae: 44.8874\n",
            "Epoch 60/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 752.3143 - mae: 22.2291 - val_loss: 2220.4216 - val_mae: 44.2066\n",
            "Epoch 61/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 838.4240 - mae: 23.0671 - val_loss: 2139.5828 - val_mae: 43.4729\n",
            "Epoch 62/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 765.4625 - mae: 22.1928 - val_loss: 2073.6702 - val_mae: 42.9032\n",
            "Epoch 63/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 761.6547 - mae: 22.1802 - val_loss: 1996.5508 - val_mae: 42.1434\n",
            "Epoch 64/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 687.6215 - mae: 21.2890 - val_loss: 1936.4873 - val_mae: 41.4862\n",
            "Epoch 65/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 573.7335 - mae: 19.1749 - val_loss: 1879.6354 - val_mae: 40.8670\n",
            "Epoch 66/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 612.7782 - mae: 19.7143 - val_loss: 1821.7129 - val_mae: 40.2153\n",
            "Epoch 67/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 462.5022 - mae: 16.4913 - val_loss: 1773.4816 - val_mae: 39.6653\n",
            "Epoch 68/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 662.0737 - mae: 21.0907 - val_loss: 1719.7535 - val_mae: 39.0389\n",
            "Epoch 69/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 478.9610 - mae: 18.0712 - val_loss: 1683.1675 - val_mae: 38.5774\n",
            "Epoch 70/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 369.9406 - mae: 16.0048 - val_loss: 1648.0400 - val_mae: 38.1119\n",
            "Epoch 71/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 444.5789 - mae: 17.0093 - val_loss: 1609.6095 - val_mae: 37.5756\n",
            "Epoch 72/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 475.6255 - mae: 17.9009 - val_loss: 1574.7682 - val_mae: 37.0705\n",
            "Epoch 73/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 465.4197 - mae: 16.9418 - val_loss: 1545.4478 - val_mae: 36.6311\n",
            "Epoch 74/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 372.6226 - mae: 15.8320 - val_loss: 1519.8751 - val_mae: 36.2175\n",
            "Epoch 75/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 354.8956 - mae: 15.2608 - val_loss: 1496.8158 - val_mae: 35.8118\n",
            "Epoch 76/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 331.0084 - mae: 14.8203 - val_loss: 1481.1366 - val_mae: 35.4984\n",
            "Epoch 77/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 280.0530 - mae: 13.1020 - val_loss: 1460.5248 - val_mae: 35.0831\n",
            "Epoch 78/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 324.1740 - mae: 14.3995 - val_loss: 1441.5033 - val_mae: 34.7036\n",
            "Epoch 79/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 219.7565 - mae: 11.3355 - val_loss: 1424.7296 - val_mae: 34.3428\n",
            "Epoch 80/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 308.0735 - mae: 13.4782 - val_loss: 1412.7855 - val_mae: 34.0064\n",
            "Epoch 81/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 252.1443 - mae: 12.3697 - val_loss: 1404.9801 - val_mae: 33.7527\n",
            "Epoch 82/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 281.0029 - mae: 13.5175 - val_loss: 1399.1525 - val_mae: 33.5278\n",
            "Epoch 83/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 156.0154 - mae: 9.6861 - val_loss: 1394.8690 - val_mae: 33.3336\n",
            "Epoch 84/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 203.2184 - mae: 10.9386 - val_loss: 1385.0299 - val_mae: 33.2875\n",
            "Epoch 85/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 187.2922 - mae: 10.6573 - val_loss: 1384.3481 - val_mae: 33.3854\n",
            "Epoch 86/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 163.9080 - mae: 9.5681 - val_loss: 1386.9728 - val_mae: 33.5054\n",
            "Epoch 87/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 154.3047 - mae: 9.6828 - val_loss: 1384.4689 - val_mae: 33.5663\n",
            "Epoch 88/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 186.4827 - mae: 10.7047 - val_loss: 1383.8878 - val_mae: 33.6360\n",
            "Epoch 89/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 162.1198 - mae: 9.4592 - val_loss: 1386.7300 - val_mae: 33.7316\n",
            "Epoch 90/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 161.6955 - mae: 9.4765 - val_loss: 1387.3325 - val_mae: 33.7843\n",
            "Epoch 91/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 130.3363 - mae: 8.6457 - val_loss: 1391.4913 - val_mae: 33.8724\n",
            "Epoch 92/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 142.1955 - mae: 8.9812 - val_loss: 1393.3862 - val_mae: 33.9279\n",
            "Epoch 93/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 87.1912 - mae: 7.1359 - val_loss: 1401.1827 - val_mae: 34.0212\n",
            "Epoch 94/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 124.2647 - mae: 8.7002 - val_loss: 1409.1036 - val_mae: 34.1305\n",
            "Epoch 95/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 132.0909 - mae: 8.7098 - val_loss: 1415.4019 - val_mae: 34.2190\n",
            "Epoch 96/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 84.2553 - mae: 6.9297 - val_loss: 1421.2252 - val_mae: 34.2925\n",
            "Epoch 97/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 87.4774 - mae: 7.2206 - val_loss: 1427.3263 - val_mae: 34.3662\n",
            "Epoch 98/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 97.8652 - mae: 7.8912 - val_loss: 1434.2845 - val_mae: 34.4328\n",
            "Epoch 99/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 58.4070 - mae: 5.8061 - val_loss: 1436.0508 - val_mae: 34.4621\n",
            "Epoch 100/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 54.8942 - mae: 5.7835 - val_loss: 1442.9199 - val_mae: 34.5343\n",
            "Epoch 101/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 67.9765 - mae: 6.2156 - val_loss: 1447.4891 - val_mae: 34.5626\n",
            "Epoch 102/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 50.6856 - mae: 5.4515 - val_loss: 1454.0084 - val_mae: 34.6143\n",
            "Epoch 103/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 65.3235 - mae: 6.4371 - val_loss: 1460.2329 - val_mae: 34.6587\n",
            "Epoch 104/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 69.5672 - mae: 6.4936 - val_loss: 1464.9794 - val_mae: 34.6872\n",
            "Epoch 105/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 35.1689 - mae: 4.5068 - val_loss: 1472.0817 - val_mae: 34.7488\n",
            "Epoch 106/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 50.5459 - mae: 5.7863 - val_loss: 1481.1971 - val_mae: 34.8220\n",
            "Epoch 107/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 54.7167 - mae: 5.6645 - val_loss: 1490.0079 - val_mae: 34.8905\n",
            "Epoch 108/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 35.7506 - mae: 4.5566 - val_loss: 1493.7018 - val_mae: 34.9080\n",
            "Epoch 109/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 41.8511 - mae: 4.8863 - val_loss: 1500.1753 - val_mae: 34.9432\n",
            "Epoch 110/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 51.3533 - mae: 5.5267 - val_loss: 1506.5765 - val_mae: 34.9739\n",
            "Epoch 111/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 36.4745 - mae: 4.4570 - val_loss: 1513.1403 - val_mae: 35.0062\n",
            "Epoch 112/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 36.7556 - mae: 4.7327 - val_loss: 1521.1211 - val_mae: 35.0372\n",
            "Epoch 113/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 34.4580 - mae: 4.5895 - val_loss: 1527.6058 - val_mae: 35.0771\n",
            "Epoch 114/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 34.5724 - mae: 4.5448 - val_loss: 1534.8710 - val_mae: 35.1344\n",
            "Epoch 115/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 25.3039 - mae: 3.9472 - val_loss: 1542.9945 - val_mae: 35.1908\n",
            "Epoch 116/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 21.8326 - mae: 3.5801 - val_loss: 1550.8628 - val_mae: 35.2235\n",
            "Epoch 117/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 19.1672 - mae: 3.3948 - val_loss: 1555.3442 - val_mae: 35.2261\n",
            "Epoch 118/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 29.9749 - mae: 4.0473 - val_loss: 1559.1271 - val_mae: 35.2260\n",
            "Epoch 119/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 23.6509 - mae: 3.7114 - val_loss: 1566.4955 - val_mae: 35.2726\n",
            "Epoch 120/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 29.1549 - mae: 4.2391 - val_loss: 1573.7408 - val_mae: 35.3261\n",
            "Epoch 121/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 25.7948 - mae: 3.8043 - val_loss: 1579.2500 - val_mae: 35.3519\n",
            "Epoch 122/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 14.7319 - mae: 2.9994 - val_loss: 1585.1017 - val_mae: 35.3919\n",
            "Epoch 123/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 20.3230 - mae: 3.4467 - val_loss: 1590.9420 - val_mae: 35.4169\n",
            "Epoch 124/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 18.5832 - mae: 3.2840 - val_loss: 1596.9067 - val_mae: 35.4538\n",
            "Epoch 125/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 21.4723 - mae: 3.4957 - val_loss: 1602.1875 - val_mae: 35.4984\n",
            "Epoch 126/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 18.6844 - mae: 3.1356 - val_loss: 1607.4268 - val_mae: 35.5304\n",
            "Epoch 127/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 16.5179 - mae: 3.1509 - val_loss: 1614.1417 - val_mae: 35.5621\n",
            "Epoch 128/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 15.6920 - mae: 2.9964 - val_loss: 1620.1051 - val_mae: 35.5834\n",
            "Epoch 129/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13.6663 - mae: 2.6887 - val_loss: 1624.8311 - val_mae: 35.6053\n",
            "Epoch 130/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13.0994 - mae: 2.6551 - val_loss: 1628.0763 - val_mae: 35.6215\n",
            "Epoch 131/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 15.0912 - mae: 2.8155 - val_loss: 1631.8148 - val_mae: 35.6284\n",
            "Epoch 132/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 9.7343 - mae: 2.3036 - val_loss: 1636.1654 - val_mae: 35.6407\n",
            "Epoch 133/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.7134 - mae: 2.1021 - val_loss: 1641.0050 - val_mae: 35.6829\n",
            "Epoch 134/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 12.9760 - mae: 2.5898 - val_loss: 1644.4232 - val_mae: 35.7034\n",
            "Epoch 135/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.4872 - mae: 2.0119 - val_loss: 1648.6517 - val_mae: 35.7304\n",
            "Epoch 136/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 12.6706 - mae: 2.7215 - val_loss: 1652.5494 - val_mae: 35.7385\n",
            "Epoch 137/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.7225 - mae: 1.8960 - val_loss: 1656.3890 - val_mae: 35.7535\n",
            "Epoch 138/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.0901 - mae: 2.0422 - val_loss: 1660.0693 - val_mae: 35.7672\n",
            "Epoch 139/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.7355 - mae: 1.7140 - val_loss: 1663.3105 - val_mae: 35.7887\n",
            "Epoch 140/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.4443 - mae: 1.9637 - val_loss: 1667.3701 - val_mae: 35.8005\n",
            "Epoch 141/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.9058 - mae: 1.5528 - val_loss: 1670.5664 - val_mae: 35.8185\n",
            "Epoch 142/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.5230 - mae: 1.7353 - val_loss: 1672.4532 - val_mae: 35.8215\n",
            "Epoch 143/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.9086 - mae: 1.7044 - val_loss: 1674.4540 - val_mae: 35.8327\n",
            "Epoch 144/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.8589 - mae: 1.6011 - val_loss: 1678.2008 - val_mae: 35.8573\n",
            "Epoch 145/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.2851 - mae: 1.7918 - val_loss: 1679.9183 - val_mae: 35.8589\n",
            "Epoch 146/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.6234 - mae: 1.5165 - val_loss: 1682.4762 - val_mae: 35.8684\n",
            "Epoch 147/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.4832 - mae: 1.3801 - val_loss: 1684.9072 - val_mae: 35.8833\n",
            "Epoch 148/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.0563 - mae: 1.4866 - val_loss: 1686.6973 - val_mae: 35.8787\n",
            "Epoch 149/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.7572 - mae: 1.4955 - val_loss: 1689.1571 - val_mae: 35.8863\n",
            "Epoch 150/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.7150 - mae: 1.3137 - val_loss: 1691.6919 - val_mae: 35.9101\n",
            "Fold 3 - Validation MAE: 35.9101\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 156ms/step - loss: 13955.4453 - mae: 117.2382 - val_loss: 13186.4170 - val_mae: 114.4645\n",
            "Epoch 2/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 13504.3975 - mae: 115.2889 - val_loss: 13167.2021 - val_mae: 114.3774\n",
            "Epoch 3/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 14327.5342 - mae: 118.9627 - val_loss: 13144.8281 - val_mae: 114.2750\n",
            "Epoch 4/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 13924.0039 - mae: 117.3951 - val_loss: 13122.5049 - val_mae: 114.1735\n",
            "Epoch 5/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13896.1211 - mae: 117.0870 - val_loss: 13093.1631 - val_mae: 114.0407\n",
            "Epoch 6/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 14221.5996 - mae: 118.4024 - val_loss: 13056.8975 - val_mae: 113.8768\n",
            "Epoch 7/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13959.6992 - mae: 117.3430 - val_loss: 13018.1982 - val_mae: 113.7015\n",
            "Epoch 8/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 14401.7773 - mae: 119.1745 - val_loss: 12976.8721 - val_mae: 113.5141\n",
            "Epoch 9/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13444.8047 - mae: 115.0647 - val_loss: 12933.2666 - val_mae: 113.3159\n",
            "Epoch 10/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13569.5879 - mae: 115.8165 - val_loss: 12885.0791 - val_mae: 113.0965\n",
            "Epoch 11/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 14142.1455 - mae: 118.0187 - val_loss: 12829.7314 - val_mae: 112.8442\n",
            "Epoch 12/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13252.2031 - mae: 114.4942 - val_loss: 12768.7266 - val_mae: 112.5650\n",
            "Epoch 13/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13092.2402 - mae: 113.5196 - val_loss: 12702.3516 - val_mae: 112.2605\n",
            "Epoch 14/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13906.7871 - mae: 117.1081 - val_loss: 12625.1240 - val_mae: 111.9061\n",
            "Epoch 15/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 13298.2637 - mae: 114.4205 - val_loss: 12535.6592 - val_mae: 111.4938\n",
            "Epoch 16/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 13165.5762 - mae: 113.7540 - val_loss: 12435.3721 - val_mae: 111.0301\n",
            "Epoch 17/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 12947.7051 - mae: 112.8675 - val_loss: 12317.8428 - val_mae: 110.4812\n",
            "Epoch 18/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 12782.2686 - mae: 112.2915 - val_loss: 12182.8359 - val_mae: 109.8459\n",
            "Epoch 19/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 12628.4580 - mae: 111.2827 - val_loss: 12033.4141 - val_mae: 109.1373\n",
            "Epoch 20/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 12547.0547 - mae: 111.3323 - val_loss: 11867.7842 - val_mae: 108.3453\n",
            "Epoch 21/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 12329.2002 - mae: 110.1539 - val_loss: 11686.1562 - val_mae: 107.4691\n",
            "Epoch 22/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 11964.6465 - mae: 108.5406 - val_loss: 11481.5225 - val_mae: 106.4683\n",
            "Epoch 23/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 11180.7754 - mae: 104.9230 - val_loss: 11254.1680 - val_mae: 105.3411\n",
            "Epoch 24/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 11130.9043 - mae: 104.4331 - val_loss: 11004.1143 - val_mae: 104.0772\n",
            "Epoch 25/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 10326.7002 - mae: 100.5134 - val_loss: 10730.8594 - val_mae: 102.6702\n",
            "Epoch 26/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 10165.2236 - mae: 99.7327 - val_loss: 10437.4775 - val_mae: 101.1287\n",
            "Epoch 27/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 9147.2822 - mae: 94.3463 - val_loss: 10122.7510 - val_mae: 99.4375\n",
            "Epoch 28/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 9436.5938 - mae: 95.5000 - val_loss: 9788.2861 - val_mae: 97.5953\n",
            "Epoch 29/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8247.1025 - mae: 89.4169 - val_loss: 9421.2412 - val_mae: 95.5190\n",
            "Epoch 30/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 8414.7354 - mae: 89.8948 - val_loss: 9013.6846 - val_mae: 93.1420\n",
            "Epoch 31/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7811.3203 - mae: 85.5983 - val_loss: 8575.3760 - val_mae: 90.4661\n",
            "Epoch 32/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6563.3638 - mae: 77.7962 - val_loss: 8109.5840 - val_mae: 87.5024\n",
            "Epoch 33/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6131.8027 - mae: 74.6546 - val_loss: 7622.0591 - val_mae: 84.2524\n",
            "Epoch 34/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5455.6704 - mae: 69.2112 - val_loss: 7125.3462 - val_mae: 80.7552\n",
            "Epoch 35/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5216.8452 - mae: 66.3436 - val_loss: 6627.4277 - val_mae: 77.0460\n",
            "Epoch 36/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4348.0557 - mae: 59.9499 - val_loss: 6133.8774 - val_mae: 73.0965\n",
            "Epoch 37/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3474.3752 - mae: 50.0488 - val_loss: 5649.9165 - val_mae: 68.9710\n",
            "Epoch 38/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2918.2334 - mae: 45.4239 - val_loss: 5160.6211 - val_mae: 64.5589\n",
            "Epoch 39/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3093.2097 - mae: 46.6803 - val_loss: 4697.7612 - val_mae: 60.0588\n",
            "Epoch 40/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2613.9038 - mae: 41.3022 - val_loss: 4267.7271 - val_mae: 56.9372\n",
            "Epoch 41/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2355.8638 - mae: 39.6463 - val_loss: 3860.7058 - val_mae: 53.9521\n",
            "Epoch 42/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2009.1034 - mae: 36.7965 - val_loss: 3499.1951 - val_mae: 50.6945\n",
            "Epoch 43/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2280.4231 - mae: 39.5025 - val_loss: 3173.1125 - val_mae: 47.4738\n",
            "Epoch 44/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1981.4526 - mae: 35.1853 - val_loss: 2895.3711 - val_mae: 46.5061\n",
            "Epoch 45/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1691.4648 - mae: 32.9129 - val_loss: 2666.9204 - val_mae: 45.4696\n",
            "Epoch 46/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2064.5066 - mae: 38.3348 - val_loss: 2465.3132 - val_mae: 44.3274\n",
            "Epoch 47/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1254.0787 - mae: 28.0257 - val_loss: 2306.5928 - val_mae: 43.1447\n",
            "Epoch 48/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1497.7482 - mae: 29.0066 - val_loss: 2161.0962 - val_mae: 41.8794\n",
            "Epoch 49/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1080.3461 - mae: 25.8988 - val_loss: 2045.2299 - val_mae: 40.6617\n",
            "Epoch 50/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1110.7959 - mae: 26.5268 - val_loss: 1952.2152 - val_mae: 39.5090\n",
            "Epoch 51/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1158.0677 - mae: 26.4715 - val_loss: 1860.1108 - val_mae: 38.3813\n",
            "Epoch 52/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 928.5016 - mae: 24.1045 - val_loss: 1775.6908 - val_mae: 37.2620\n",
            "Epoch 53/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1119.5718 - mae: 26.6253 - val_loss: 1700.2822 - val_mae: 36.1798\n",
            "Epoch 54/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 909.4890 - mae: 24.4194 - val_loss: 1635.2994 - val_mae: 35.1554\n",
            "Epoch 55/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1148.0461 - mae: 27.9926 - val_loss: 1574.5778 - val_mae: 34.1754\n",
            "Epoch 56/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 948.9872 - mae: 25.0442 - val_loss: 1522.7147 - val_mae: 33.2777\n",
            "Epoch 57/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 753.2571 - mae: 22.0449 - val_loss: 1479.2399 - val_mae: 32.3937\n",
            "Epoch 58/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 648.4480 - mae: 19.7172 - val_loss: 1441.0944 - val_mae: 31.5503\n",
            "Epoch 59/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 957.7185 - mae: 24.8947 - val_loss: 1408.5464 - val_mae: 30.7056\n",
            "Epoch 60/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 936.7550 - mae: 24.9908 - val_loss: 1378.6466 - val_mae: 30.2836\n",
            "Epoch 61/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 812.7549 - mae: 22.9452 - val_loss: 1359.5433 - val_mae: 30.3114\n",
            "Epoch 62/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 565.0704 - mae: 19.0575 - val_loss: 1343.9414 - val_mae: 30.2653\n",
            "Epoch 63/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 756.4192 - mae: 21.6961 - val_loss: 1330.2872 - val_mae: 30.2126\n",
            "Epoch 64/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 667.4125 - mae: 21.0447 - val_loss: 1322.9525 - val_mae: 30.1684\n",
            "Epoch 65/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 631.1579 - mae: 19.1539 - val_loss: 1322.6903 - val_mae: 30.1146\n",
            "Epoch 66/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 524.3051 - mae: 17.8327 - val_loss: 1320.1837 - val_mae: 30.0256\n",
            "Epoch 67/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 566.5029 - mae: 18.4037 - val_loss: 1317.7495 - val_mae: 29.9072\n",
            "Epoch 68/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 418.6252 - mae: 15.6274 - val_loss: 1317.7118 - val_mae: 29.7910\n",
            "Epoch 69/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 550.1879 - mae: 17.7743 - val_loss: 1321.9225 - val_mae: 29.6988\n",
            "Epoch 70/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 428.3400 - mae: 16.2269 - val_loss: 1320.6298 - val_mae: 29.5825\n",
            "Epoch 71/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 452.5071 - mae: 15.9233 - val_loss: 1319.0576 - val_mae: 29.4581\n",
            "Epoch 72/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 346.2571 - mae: 14.1390 - val_loss: 1320.0739 - val_mae: 29.3188\n",
            "Epoch 73/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 367.8688 - mae: 15.1292 - val_loss: 1320.5223 - val_mae: 29.1645\n",
            "Epoch 74/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 344.8292 - mae: 13.9960 - val_loss: 1323.4957 - val_mae: 29.0354\n",
            "Epoch 75/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 330.2198 - mae: 13.8001 - val_loss: 1322.3676 - val_mae: 28.8849\n",
            "Epoch 76/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 345.1588 - mae: 13.7540 - val_loss: 1324.7499 - val_mae: 28.7574\n",
            "Epoch 77/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 257.9731 - mae: 12.2856 - val_loss: 1325.6110 - val_mae: 28.6053\n",
            "Epoch 78/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 243.0928 - mae: 11.6384 - val_loss: 1322.4170 - val_mae: 28.4374\n",
            "Epoch 79/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 213.5209 - mae: 10.9243 - val_loss: 1326.9713 - val_mae: 28.3173\n",
            "Epoch 80/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 224.9065 - mae: 11.3000 - val_loss: 1327.7109 - val_mae: 28.1612\n",
            "Epoch 81/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 238.6422 - mae: 11.8167 - val_loss: 1331.0826 - val_mae: 28.0161\n",
            "Epoch 82/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 195.2146 - mae: 10.2662 - val_loss: 1337.4871 - val_mae: 27.8954\n",
            "Epoch 83/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 216.5302 - mae: 11.1947 - val_loss: 1337.1915 - val_mae: 27.7250\n",
            "Epoch 84/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 157.1146 - mae: 9.6658 - val_loss: 1336.6456 - val_mae: 27.5821\n",
            "Epoch 85/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 205.7961 - mae: 10.8191 - val_loss: 1343.5421 - val_mae: 27.4567\n",
            "Epoch 86/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 163.2952 - mae: 9.8719 - val_loss: 1338.5936 - val_mae: 27.2867\n",
            "Epoch 87/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 151.3339 - mae: 9.2711 - val_loss: 1337.9728 - val_mae: 27.1209\n",
            "Epoch 88/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 173.8895 - mae: 10.1122 - val_loss: 1346.3005 - val_mae: 27.0048\n",
            "Epoch 89/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 122.9271 - mae: 8.4600 - val_loss: 1341.1112 - val_mae: 26.8318\n",
            "Epoch 90/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 138.7970 - mae: 8.8892 - val_loss: 1338.2085 - val_mae: 26.6851\n",
            "Epoch 91/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 174.9786 - mae: 10.0215 - val_loss: 1342.5560 - val_mae: 26.6210\n",
            "Epoch 92/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 138.7224 - mae: 8.5746 - val_loss: 1344.7333 - val_mae: 26.6690\n",
            "Epoch 93/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 119.2937 - mae: 8.3866 - val_loss: 1343.4199 - val_mae: 26.6752\n",
            "Epoch 94/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 79.6842 - mae: 6.5318 - val_loss: 1335.7578 - val_mae: 26.6091\n",
            "Epoch 95/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 82.0679 - mae: 6.7179 - val_loss: 1336.2692 - val_mae: 26.6356\n",
            "Epoch 96/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 94.0060 - mae: 7.2018 - val_loss: 1335.0409 - val_mae: 26.6425\n",
            "Epoch 97/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 106.2441 - mae: 7.3242 - val_loss: 1331.8922 - val_mae: 26.6014\n",
            "Epoch 98/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 99.0012 - mae: 7.6435 - val_loss: 1332.5809 - val_mae: 26.6602\n",
            "Epoch 99/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 65.0494 - mae: 6.2024 - val_loss: 1335.0133 - val_mae: 26.6858\n",
            "Epoch 100/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 56.4239 - mae: 5.2563 - val_loss: 1330.8893 - val_mae: 26.6274\n",
            "Epoch 101/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 61.8096 - mae: 6.0307 - val_loss: 1330.7748 - val_mae: 26.6562\n",
            "Epoch 102/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 52.3561 - mae: 4.9861 - val_loss: 1329.6693 - val_mae: 26.6604\n",
            "Epoch 103/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 63.3553 - mae: 5.7589 - val_loss: 1332.3634 - val_mae: 26.6965\n",
            "Epoch 104/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 44.6116 - mae: 4.9291 - val_loss: 1331.0673 - val_mae: 26.7250\n",
            "Epoch 105/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 47.0899 - mae: 4.9718 - val_loss: 1323.7697 - val_mae: 26.6824\n",
            "Epoch 106/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 36.1321 - mae: 4.3701 - val_loss: 1319.9150 - val_mae: 26.6622\n",
            "Epoch 107/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 35.5208 - mae: 4.2923 - val_loss: 1317.4886 - val_mae: 26.6647\n",
            "Epoch 108/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 36.0910 - mae: 4.4539 - val_loss: 1315.5343 - val_mae: 26.6657\n",
            "Epoch 109/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 52.5378 - mae: 4.9347 - val_loss: 1318.9272 - val_mae: 26.6952\n",
            "Epoch 110/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 27.4648 - mae: 3.8144 - val_loss: 1313.8231 - val_mae: 26.6873\n",
            "Epoch 111/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 36.9636 - mae: 4.4045 - val_loss: 1313.3031 - val_mae: 26.6829\n",
            "Epoch 112/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 28.3560 - mae: 3.5714 - val_loss: 1309.7059 - val_mae: 26.6671\n",
            "Epoch 113/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 33.9646 - mae: 4.2178 - val_loss: 1305.9698 - val_mae: 26.6431\n",
            "Epoch 114/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 39.6641 - mae: 4.2797 - val_loss: 1303.1897 - val_mae: 26.6209\n",
            "Epoch 115/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 30.7979 - mae: 3.9591 - val_loss: 1303.1815 - val_mae: 26.6427\n",
            "Epoch 116/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 25.1779 - mae: 3.5217 - val_loss: 1297.5950 - val_mae: 26.5894\n",
            "Epoch 117/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 18.0464 - mae: 2.8764 - val_loss: 1294.7155 - val_mae: 26.5710\n",
            "Epoch 118/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 31.4951 - mae: 3.7758 - val_loss: 1292.6769 - val_mae: 26.5450\n",
            "Epoch 119/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 30.0031 - mae: 3.7255 - val_loss: 1288.2596 - val_mae: 26.5143\n",
            "Epoch 120/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 25.3374 - mae: 3.1782 - val_loss: 1286.3123 - val_mae: 26.5152\n",
            "Epoch 121/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 23.8572 - mae: 3.1799 - val_loss: 1280.9066 - val_mae: 26.4869\n",
            "Epoch 122/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 13.9115 - mae: 2.7318 - val_loss: 1277.6411 - val_mae: 26.4798\n",
            "Epoch 123/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 14.6522 - mae: 2.4807 - val_loss: 1277.7262 - val_mae: 26.4656\n",
            "Epoch 124/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 22.0816 - mae: 3.1313 - val_loss: 1277.9857 - val_mae: 26.4709\n",
            "Epoch 125/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 13.9307 - mae: 2.5977 - val_loss: 1275.1309 - val_mae: 26.4446\n",
            "Epoch 126/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9.6322 - mae: 2.1493 - val_loss: 1274.3085 - val_mae: 26.4238\n",
            "Epoch 127/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 17.6667 - mae: 2.6868 - val_loss: 1270.9266 - val_mae: 26.3778\n",
            "Epoch 128/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.3889 - mae: 2.2807 - val_loss: 1269.9108 - val_mae: 26.3883\n",
            "Epoch 129/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 10.0669 - mae: 2.0595 - val_loss: 1267.8174 - val_mae: 26.3618\n",
            "Epoch 130/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 10.2123 - mae: 2.1202 - val_loss: 1267.1180 - val_mae: 26.3412\n",
            "Epoch 131/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 10.1864 - mae: 2.1967 - val_loss: 1267.7509 - val_mae: 26.3517\n",
            "Epoch 132/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 8.4788 - mae: 1.9269 - val_loss: 1264.1937 - val_mae: 26.3154\n",
            "Epoch 133/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 8.4469 - mae: 2.0492 - val_loss: 1261.1355 - val_mae: 26.2971\n",
            "Epoch 134/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 11.0862 - mae: 2.0198 - val_loss: 1258.0137 - val_mae: 26.2649\n",
            "Epoch 135/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 10.5082 - mae: 2.0323 - val_loss: 1254.7144 - val_mae: 26.2407\n",
            "Epoch 136/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 9.6404 - mae: 1.8728 - val_loss: 1250.3070 - val_mae: 26.2005\n",
            "Epoch 137/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.5928 - mae: 1.4914 - val_loss: 1246.8447 - val_mae: 26.1855\n",
            "Epoch 138/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.3074 - mae: 1.6702 - val_loss: 1245.8832 - val_mae: 26.1865\n",
            "Epoch 139/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.3089 - mae: 1.9832 - val_loss: 1245.4369 - val_mae: 26.1761\n",
            "Epoch 140/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.2641 - mae: 1.4463 - val_loss: 1243.9712 - val_mae: 26.1653\n",
            "Epoch 141/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.5298 - mae: 1.2863 - val_loss: 1242.4904 - val_mae: 26.1569\n",
            "Epoch 142/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.3597 - mae: 1.6408 - val_loss: 1241.2206 - val_mae: 26.1423\n",
            "Epoch 143/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.2567 - mae: 1.2113 - val_loss: 1238.3049 - val_mae: 26.1150\n",
            "Epoch 144/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.8147 - mae: 1.5904 - val_loss: 1238.4929 - val_mae: 26.1094\n",
            "Epoch 145/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.7976 - mae: 1.0974 - val_loss: 1236.6606 - val_mae: 26.0986\n",
            "Epoch 146/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.5588 - mae: 1.0684 - val_loss: 1234.2854 - val_mae: 26.0820\n",
            "Epoch 147/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.1959 - mae: 1.0476 - val_loss: 1233.2433 - val_mae: 26.0700\n",
            "Epoch 148/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.4767 - mae: 0.9932 - val_loss: 1233.4443 - val_mae: 26.0746\n",
            "Epoch 149/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.0769 - mae: 1.3715 - val_loss: 1232.4053 - val_mae: 26.0648\n",
            "Epoch 150/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.7804 - mae: 0.9916 - val_loss: 1229.7917 - val_mae: 26.0463\n",
            "Fold 4 - Validation MAE: 26.0463\n",
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - loss: 13522.8711 - mae: 115.6312 - val_loss: 14434.7383 - val_mae: 119.5247\n",
            "Epoch 2/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 14005.9297 - mae: 117.4361 - val_loss: 14384.0508 - val_mae: 119.3091\n",
            "Epoch 3/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13228.4219 - mae: 114.1609 - val_loss: 14330.6182 - val_mae: 119.0818\n",
            "Epoch 4/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13403.4014 - mae: 115.0472 - val_loss: 14273.3564 - val_mae: 118.8384\n",
            "Epoch 5/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13421.5273 - mae: 114.8995 - val_loss: 14211.4971 - val_mae: 118.5766\n",
            "Epoch 6/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13414.8281 - mae: 115.2435 - val_loss: 14144.1768 - val_mae: 118.2919\n",
            "Epoch 7/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 13284.4473 - mae: 114.4893 - val_loss: 14072.5381 - val_mae: 117.9884\n",
            "Epoch 8/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 13403.1953 - mae: 114.9561 - val_loss: 13993.3721 - val_mae: 117.6506\n",
            "Epoch 9/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 12983.9248 - mae: 113.1814 - val_loss: 13903.0742 - val_mae: 117.2635\n",
            "Epoch 10/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 13182.6250 - mae: 114.1008 - val_loss: 13797.7734 - val_mae: 116.8106\n",
            "Epoch 11/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13027.3916 - mae: 113.4693 - val_loss: 13673.8594 - val_mae: 116.2714\n",
            "Epoch 12/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13093.8047 - mae: 113.6515 - val_loss: 13534.0361 - val_mae: 115.6583\n",
            "Epoch 13/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 12465.4209 - mae: 110.9796 - val_loss: 13369.2158 - val_mae: 114.9315\n",
            "Epoch 14/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 12249.6816 - mae: 109.7416 - val_loss: 13184.4072 - val_mae: 114.1095\n",
            "Epoch 15/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 12099.6318 - mae: 109.1076 - val_loss: 12976.1689 - val_mae: 113.1722\n",
            "Epoch 16/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 11999.3281 - mae: 108.5119 - val_loss: 12741.9971 - val_mae: 112.1064\n",
            "Epoch 17/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 11837.5039 - mae: 107.7690 - val_loss: 12479.0078 - val_mae: 110.8971\n",
            "Epoch 18/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 11174.5059 - mae: 104.6716 - val_loss: 12186.9883 - val_mae: 109.5336\n",
            "Epoch 19/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10978.6973 - mae: 103.5841 - val_loss: 11865.6338 - val_mae: 108.0061\n",
            "Epoch 20/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10311.2754 - mae: 100.2085 - val_loss: 11501.5850 - val_mae: 106.2477\n",
            "Epoch 21/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9924.1875 - mae: 98.2763 - val_loss: 11094.0420 - val_mae: 104.2306\n",
            "Epoch 22/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 10062.2070 - mae: 98.6061 - val_loss: 10657.5771 - val_mae: 102.0063\n",
            "Epoch 23/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8862.0898 - mae: 92.5815 - val_loss: 10171.8271 - val_mae: 99.4661\n",
            "Epoch 24/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8515.6641 - mae: 90.4504 - val_loss: 9657.6572 - val_mae: 96.6766\n",
            "Epoch 25/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7543.6289 - mae: 84.8582 - val_loss: 9105.1494 - val_mae: 93.5591\n",
            "Epoch 26/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6997.3179 - mae: 80.5484 - val_loss: 8531.5908 - val_mae: 90.1788\n",
            "Epoch 27/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5768.8145 - mae: 71.7581 - val_loss: 7931.5659 - val_mae: 86.4528\n",
            "Epoch 28/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5670.2983 - mae: 71.4607 - val_loss: 7320.3569 - val_mae: 82.4242\n",
            "Epoch 29/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4444.8979 - mae: 62.2538 - val_loss: 6707.9512 - val_mae: 78.1110\n",
            "Epoch 30/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4158.3442 - mae: 58.7894 - val_loss: 6123.1992 - val_mae: 73.6594\n",
            "Epoch 31/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3103.9287 - mae: 50.0797 - val_loss: 5565.4741 - val_mae: 69.0794\n",
            "Epoch 32/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2708.7036 - mae: 44.6703 - val_loss: 5046.5093 - val_mae: 64.3848\n",
            "Epoch 33/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2201.6885 - mae: 38.1523 - val_loss: 4609.7485 - val_mae: 60.0026\n",
            "Epoch 34/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2030.3992 - mae: 36.1814 - val_loss: 4245.4976 - val_mae: 56.0362\n",
            "Epoch 35/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1906.0740 - mae: 35.4650 - val_loss: 3966.4031 - val_mae: 52.8749\n",
            "Epoch 36/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1724.0503 - mae: 34.4798 - val_loss: 3751.2136 - val_mae: 51.3736\n",
            "Epoch 37/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1943.1564 - mae: 35.6776 - val_loss: 3614.8562 - val_mae: 50.6821\n",
            "Epoch 38/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1686.5980 - mae: 31.3322 - val_loss: 3524.1445 - val_mae: 50.1878\n",
            "Epoch 39/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1412.1779 - mae: 30.7698 - val_loss: 3445.7910 - val_mae: 49.6461\n",
            "Epoch 40/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1608.3884 - mae: 30.8120 - val_loss: 3432.0032 - val_mae: 49.5627\n",
            "Epoch 41/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1322.0229 - mae: 28.6872 - val_loss: 3431.1670 - val_mae: 49.4318\n",
            "Epoch 42/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1059.6992 - mae: 24.8928 - val_loss: 3437.8313 - val_mae: 49.3524\n",
            "Epoch 43/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 935.7368 - mae: 23.7415 - val_loss: 3446.5996 - val_mae: 49.6073\n",
            "Epoch 44/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 652.4219 - mae: 19.4307 - val_loss: 3462.4714 - val_mae: 50.2042\n",
            "Epoch 45/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 859.6689 - mae: 22.6425 - val_loss: 3465.6057 - val_mae: 50.5870\n",
            "Epoch 46/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 623.2756 - mae: 18.3790 - val_loss: 3460.2246 - val_mae: 50.7989\n",
            "Epoch 47/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 946.7037 - mae: 23.7005 - val_loss: 3456.9368 - val_mae: 51.0507\n",
            "Epoch 48/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 657.7769 - mae: 18.7271 - val_loss: 3435.7507 - val_mae: 51.0375\n",
            "Epoch 49/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 774.2327 - mae: 21.3271 - val_loss: 3398.2744 - val_mae: 50.8038\n",
            "Epoch 50/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 590.3613 - mae: 18.9135 - val_loss: 3363.3037 - val_mae: 50.5444\n",
            "Epoch 51/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 429.8880 - mae: 15.1741 - val_loss: 3338.4050 - val_mae: 50.3947\n",
            "Epoch 52/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 441.5284 - mae: 16.4286 - val_loss: 3299.0491 - val_mae: 50.0653\n",
            "Epoch 53/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 410.4087 - mae: 15.1673 - val_loss: 3275.3801 - val_mae: 49.9255\n",
            "Epoch 54/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 456.4936 - mae: 16.2400 - val_loss: 3245.9688 - val_mae: 49.6898\n",
            "Epoch 55/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 371.7295 - mae: 14.1953 - val_loss: 3218.3652 - val_mae: 49.4974\n",
            "Epoch 56/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 402.3372 - mae: 15.3063 - val_loss: 3198.6257 - val_mae: 49.3846\n",
            "Epoch 57/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 304.6288 - mae: 13.3469 - val_loss: 3177.0703 - val_mae: 49.2268\n",
            "Epoch 58/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 376.2270 - mae: 14.4694 - val_loss: 3161.6299 - val_mae: 49.1411\n",
            "Epoch 59/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 253.4695 - mae: 12.5234 - val_loss: 3151.1230 - val_mae: 49.1218\n",
            "Epoch 60/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 308.0818 - mae: 13.6846 - val_loss: 3138.9231 - val_mae: 49.0644\n",
            "Epoch 61/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 260.4427 - mae: 12.1897 - val_loss: 3126.6934 - val_mae: 48.9790\n",
            "Epoch 62/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 246.7383 - mae: 12.0766 - val_loss: 3117.1326 - val_mae: 48.9523\n",
            "Epoch 63/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 236.6425 - mae: 12.1383 - val_loss: 3105.4919 - val_mae: 48.8964\n",
            "Epoch 64/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 192.3409 - mae: 10.4938 - val_loss: 3095.4084 - val_mae: 48.8590\n",
            "Epoch 65/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 200.7163 - mae: 11.3094 - val_loss: 3083.4929 - val_mae: 48.8068\n",
            "Epoch 66/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 136.6358 - mae: 8.9374 - val_loss: 3073.2087 - val_mae: 48.7329\n",
            "Epoch 67/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 195.7329 - mae: 10.3522 - val_loss: 3059.1414 - val_mae: 48.6012\n",
            "Epoch 68/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 208.8366 - mae: 11.4789 - val_loss: 3046.0449 - val_mae: 48.4915\n",
            "Epoch 69/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 154.4963 - mae: 9.0891 - val_loss: 3036.3350 - val_mae: 48.4228\n",
            "Epoch 70/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 157.4461 - mae: 9.2648 - val_loss: 3028.8848 - val_mae: 48.3721\n",
            "Epoch 71/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 111.2282 - mae: 8.4017 - val_loss: 3028.0752 - val_mae: 48.4105\n",
            "Epoch 72/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 95.3598 - mae: 7.1490 - val_loss: 3024.7966 - val_mae: 48.4224\n",
            "Epoch 73/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 135.1711 - mae: 8.3945 - val_loss: 3010.8542 - val_mae: 48.3004\n",
            "Epoch 74/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 99.1205 - mae: 7.7584 - val_loss: 3004.3523 - val_mae: 48.2443\n",
            "Epoch 75/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 115.2252 - mae: 7.9885 - val_loss: 2993.2312 - val_mae: 48.1252\n",
            "Epoch 76/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 105.5019 - mae: 7.2282 - val_loss: 2987.7473 - val_mae: 48.0948\n",
            "Epoch 77/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 120.6762 - mae: 8.4708 - val_loss: 2982.5564 - val_mae: 48.0649\n",
            "Epoch 78/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 69.4780 - mae: 6.4149 - val_loss: 2977.5459 - val_mae: 48.0373\n",
            "Epoch 79/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 73.8863 - mae: 6.3851 - val_loss: 2975.5098 - val_mae: 48.0616\n",
            "Epoch 80/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 84.0372 - mae: 6.6103 - val_loss: 2961.7566 - val_mae: 47.9021\n",
            "Epoch 81/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 57.6149 - mae: 5.7033 - val_loss: 2956.9895 - val_mae: 47.8598\n",
            "Epoch 82/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 65.2173 - mae: 6.1463 - val_loss: 2951.7822 - val_mae: 47.8204\n",
            "Epoch 83/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 60.5927 - mae: 5.8859 - val_loss: 2947.5273 - val_mae: 47.7957\n",
            "Epoch 84/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 44.1717 - mae: 5.0754 - val_loss: 2944.8711 - val_mae: 47.7833\n",
            "Epoch 85/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 46.1373 - mae: 5.0562 - val_loss: 2936.7891 - val_mae: 47.6834\n",
            "Epoch 86/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 32.0153 - mae: 4.1763 - val_loss: 2932.0930 - val_mae: 47.6326\n",
            "Epoch 87/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 45.4218 - mae: 5.1615 - val_loss: 2928.2637 - val_mae: 47.6028\n",
            "Epoch 88/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 54.7686 - mae: 5.6025 - val_loss: 2923.6790 - val_mae: 47.5499\n",
            "Epoch 89/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 29.2673 - mae: 4.1559 - val_loss: 2920.7129 - val_mae: 47.5225\n",
            "Epoch 90/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 31.1239 - mae: 4.3466 - val_loss: 2920.5129 - val_mae: 47.5366\n",
            "Epoch 91/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 28.1495 - mae: 4.1083 - val_loss: 2920.9138 - val_mae: 47.5561\n",
            "Epoch 92/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 39.9818 - mae: 4.3607 - val_loss: 2918.5830 - val_mae: 47.5469\n",
            "Epoch 93/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 37.0814 - mae: 4.3653 - val_loss: 2916.2981 - val_mae: 47.5309\n",
            "Epoch 94/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 36.2113 - mae: 4.2394 - val_loss: 2913.5579 - val_mae: 47.5102\n",
            "Epoch 95/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 20.7661 - mae: 3.1920 - val_loss: 2909.8477 - val_mae: 47.4646\n",
            "Epoch 96/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 24.3728 - mae: 3.6120 - val_loss: 2909.2634 - val_mae: 47.4836\n",
            "Epoch 97/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 19.5400 - mae: 3.1700 - val_loss: 2907.2051 - val_mae: 47.4627\n",
            "Epoch 98/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 26.6458 - mae: 3.6910 - val_loss: 2902.5188 - val_mae: 47.4167\n",
            "Epoch 99/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 14.9248 - mae: 2.9157 - val_loss: 2901.9775 - val_mae: 47.4334\n",
            "Epoch 100/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13.8171 - mae: 2.6955 - val_loss: 2903.5823 - val_mae: 47.4695\n",
            "Epoch 101/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13.9868 - mae: 2.4861 - val_loss: 2902.1699 - val_mae: 47.4461\n",
            "Epoch 102/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 15.4519 - mae: 2.7935 - val_loss: 2900.1543 - val_mae: 47.4351\n",
            "Epoch 103/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 14.2586 - mae: 2.6622 - val_loss: 2897.0752 - val_mae: 47.4163\n",
            "Epoch 104/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.3449 - mae: 2.2334 - val_loss: 2895.3630 - val_mae: 47.4106\n",
            "Epoch 105/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 16.7061 - mae: 2.5631 - val_loss: 2892.8933 - val_mae: 47.3927\n",
            "Epoch 106/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10.7696 - mae: 2.2705 - val_loss: 2890.3992 - val_mae: 47.3791\n",
            "Epoch 107/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.0273 - mae: 2.2375 - val_loss: 2890.2637 - val_mae: 47.3937\n",
            "Epoch 108/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13.7504 - mae: 2.3382 - val_loss: 2888.0681 - val_mae: 47.3727\n",
            "Epoch 109/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.7014 - mae: 1.9650 - val_loss: 2887.5427 - val_mae: 47.3788\n",
            "Epoch 110/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.8369 - mae: 2.0776 - val_loss: 2887.5559 - val_mae: 47.3841\n",
            "Epoch 111/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 12.2922 - mae: 2.2677 - val_loss: 2884.5078 - val_mae: 47.3546\n",
            "Epoch 112/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.7733 - mae: 1.7171 - val_loss: 2883.1833 - val_mae: 47.3465\n",
            "Epoch 113/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10.2911 - mae: 2.0024 - val_loss: 2882.0925 - val_mae: 47.3380\n",
            "Epoch 114/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.0810 - mae: 1.3240 - val_loss: 2881.4551 - val_mae: 47.3355\n",
            "Epoch 115/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.9693 - mae: 1.8866 - val_loss: 2880.2747 - val_mae: 47.3222\n",
            "Epoch 116/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.3775 - mae: 1.7840 - val_loss: 2880.1924 - val_mae: 47.3305\n",
            "Epoch 117/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.7983 - mae: 1.3198 - val_loss: 2880.5647 - val_mae: 47.3497\n",
            "Epoch 118/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.5831 - mae: 1.3288 - val_loss: 2878.5242 - val_mae: 47.3342\n",
            "Epoch 119/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.9550 - mae: 1.0937 - val_loss: 2877.3372 - val_mae: 47.3336\n",
            "Epoch 120/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.0030 - mae: 1.1496 - val_loss: 2875.6423 - val_mae: 47.3231\n",
            "Epoch 121/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.6062 - mae: 1.1049 - val_loss: 2873.5281 - val_mae: 47.2982\n",
            "Epoch 122/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.3477 - mae: 1.0521 - val_loss: 2873.0618 - val_mae: 47.2920\n",
            "Epoch 123/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.5623 - mae: 1.1360 - val_loss: 2872.7969 - val_mae: 47.2990\n",
            "Epoch 124/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.1568 - mae: 1.2992 - val_loss: 2871.5176 - val_mae: 47.2913\n",
            "Epoch 125/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.6404 - mae: 0.8823 - val_loss: 2870.5234 - val_mae: 47.2848\n",
            "Epoch 126/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.6342 - mae: 0.9154 - val_loss: 2870.0383 - val_mae: 47.2835\n",
            "Epoch 127/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.9330 - mae: 1.0422 - val_loss: 2869.5505 - val_mae: 47.2816\n",
            "Epoch 128/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.7227 - mae: 0.8050 - val_loss: 2869.7761 - val_mae: 47.2946\n",
            "Epoch 129/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.1271 - mae: 0.7881 - val_loss: 2869.4014 - val_mae: 47.2981\n",
            "Epoch 130/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.3835 - mae: 0.9583 - val_loss: 2868.4736 - val_mae: 47.2938\n",
            "Epoch 131/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3196 - mae: 0.6723 - val_loss: 2868.4348 - val_mae: 47.3009\n",
            "Epoch 132/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.9727 - mae: 0.8457 - val_loss: 2867.6926 - val_mae: 47.2958\n",
            "Epoch 133/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.9436 - mae: 0.9523 - val_loss: 2866.7302 - val_mae: 47.2893\n",
            "Epoch 134/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0458 - mae: 0.5513 - val_loss: 2866.7227 - val_mae: 47.2948\n",
            "Epoch 135/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.5103 - mae: 0.6491 - val_loss: 2866.3145 - val_mae: 47.2927\n",
            "Epoch 136/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.3459 - mae: 0.8125 - val_loss: 2864.6794 - val_mae: 47.2753\n",
            "Epoch 137/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3064 - mae: 0.5939 - val_loss: 2864.4258 - val_mae: 47.2745\n",
            "Epoch 138/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.9750 - mae: 0.6764 - val_loss: 2863.9133 - val_mae: 47.2688\n",
            "Epoch 139/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.8940 - mae: 0.6863 - val_loss: 2863.5320 - val_mae: 47.2672\n",
            "Epoch 140/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.7656 - mae: 0.4929 - val_loss: 2863.5461 - val_mae: 47.2760\n",
            "Epoch 141/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6654 - mae: 0.6278 - val_loss: 2862.9543 - val_mae: 47.2714\n",
            "Epoch 142/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0371 - mae: 0.5560 - val_loss: 2862.7773 - val_mae: 47.2776\n",
            "Epoch 143/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6611 - mae: 0.4501 - val_loss: 2862.4221 - val_mae: 47.2805\n",
            "Epoch 144/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.4563 - mae: 0.5808 - val_loss: 2861.1663 - val_mae: 47.2691\n",
            "Epoch 145/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.5337 - mae: 0.3859 - val_loss: 2860.8489 - val_mae: 47.2693\n",
            "Epoch 146/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.3006 - mae: 0.5605 - val_loss: 2859.8818 - val_mae: 47.2570\n",
            "Epoch 147/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.1744 - mae: 0.5235 - val_loss: 2859.4617 - val_mae: 47.2524\n",
            "Epoch 148/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6369 - mae: 0.3695 - val_loss: 2859.1191 - val_mae: 47.2506\n",
            "Epoch 149/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.6461 - mae: 0.4095 - val_loss: 2859.0703 - val_mae: 47.2541\n",
            "Epoch 150/150\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4027 - mae: 0.3242 - val_loss: 2858.8669 - val_mae: 47.2551\n",
            "Fold 5 - Validation MAE: 47.2551\n",
            "\n",
            "Average Validation MAE: 35.1227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/NBA_model.keras')"
      ],
      "metadata": {
        "id": "UUoZY8axvuxy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/My Drive/NBA_model.keras')\n",
        "print(team_dict.keys())\n",
        "team = str(input(\"Enter a team from the seleciton above (ensure exact spelling): \"))\n",
        "temp = getRecentGames(team)\n",
        "temp.pop(\"TARGET\")\n",
        "scaler = joblib.load(\"/content/drive/My Drive/NBA_scaler.pkl\")\n",
        "\n",
        "if (temp.isna().sum().sum() > 0):\n",
        "  print(\"There are some NA's with the input data for \" + team +\".\")\n",
        "  print(\"Would you like to impute the median from the training data for these values? (may result in inaccurate prediction)\")\n",
        "  ans = str(input(\"Y/N: \"))\n",
        "  if (ans == \"Y\"):\n",
        "    temp = temp.fillna(X.median())\n",
        "    scaledNewData = scaler.transform(temp)\n",
        "\n",
        "    #print(temp)\n",
        "\n",
        "    prediction = model.predict(scaledNewData)\n",
        "    print(\"The model predicts \" + str(prediction[0]) + \" points\")\n",
        "\n",
        "  else:\n",
        "    print(\"Exiting...\")\n",
        "\n",
        "else:\n",
        "  scaledNewData = scaler.transform(temp)\n",
        "\n",
        "  prediction = model.predict(scaledNewData)\n",
        "  print(\"The model predicts \" + str(prediction[0]) + \" points\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwRGbrOswJ0T",
        "outputId": "456b6163-d08b-4dda-9b2c-2aa4f50f49b0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['atlanta hawks', 'boston celtics', 'cleveland cavaliers', 'new orleans pelicans', 'chicago bulls', 'dallas mavericks', 'denver nuggets', 'golden state warriors', 'houston rockets', 'los angeles clippers', 'los angeles lakers', 'miami heat', 'milwaukee bucks', 'minnesota timberwolves', 'brooklyn nets', 'new york knicks', 'orlando magic', 'indiana pacers', 'philadelphia 76ers', 'phoenix suns', 'portland trail blazers', 'sacramento kings', 'san antonio spurs', 'oklahoma city thunder', 'toronto raptors', 'utah jazz', 'memphis grizzlies', 'washington wizards', 'detroit pistons', 'charlotte hornets'])\n",
            "Enter a team from the seleciton above (ensure exact spelling): dallas mavericks\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "The model predicts [133.08704] points\n"
          ]
        }
      ]
    }
  ]
}